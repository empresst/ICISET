{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thDUSAgYLJEe",
        "outputId": "1afe9e80-ca54-4a84-b924-c7b6ceaa3ef3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PIc_Kgm3upH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "# Set floating point precision option for pandas\n",
        "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
        "\n",
        "# Import seaborn library and set context and style\n",
        "import seaborn as sns\n",
        "sns.set_context(\"paper\", font_scale=1.3)\n",
        "sns.set_style('white')\n",
        "\n",
        "# Import warnings and set filter to ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import time library\n",
        "from time import time\n",
        "\n",
        "# Import matplotlib ticker and scipy stats\n",
        "import matplotlib.ticker as tkr\n",
        "from scipy import stats\n",
        "\n",
        "# Import statistical tools for time series analysis\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "# Import preprocessing from sklearn\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Import partial autocorrelation function from statsmodels\n",
        "from statsmodels.tsa.stattools import pacf\n",
        "\n",
        "# Enable inline plotting in Jupyter Notebook\n",
        "%matplotlib inline\n",
        "\n",
        "# Import math library\n",
        "import math\n",
        "\n",
        "# Import necessary functions from keras\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import *\n",
        "\n",
        "# Import MinMaxScaler from sklearn\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Import mean squared error and mean absolute error from sklearn\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Import early stopping from keras callbacks\n",
        "from keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZszqeqrPy1Dg"
      },
      "outputs": [],
      "source": [
        "# data = pd.read_csv('/content/drive/MyDrive/household_power_consumption.txt', delimiter=';')\n",
        "# data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCrGqr2k38ZY"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# #Ekhan theke\n",
        "# sample_size = int(0.01 * len(data))  # 1% sample size\n",
        "# sampled_data = data.sample(sample_size)\n",
        "# sampled_data.head(5)\n",
        "\n",
        "# data2 = sampled_data\n",
        "# #Eituk\n",
        "\n",
        "\n",
        "#df = pd.DataFrame(data2)\n",
        "#df.to_csv('/content/drive/MyDrive/data_no_index.csv', index=False)  # Save without row index\n",
        "#df.to_csv('/content/drive/MyDrive/individual+household+electric+power+consumption/data_tab_delimited.csv', sep='\\t')\n",
        "#df.to_csv('/content/drive/MyDrive/individual+household+electric+power+consumption/my_data.csv', mode='a', header=False)\n",
        "# float_column = data[\"Global_active_power\"]\n",
        "# average = float_column.mean()\n",
        "# median = float_column.median()\n",
        "# minimum = float_column.min()\n",
        "# maximum = float_column.max()\n",
        "\n",
        "\n",
        "# grouped_data = data.groupby(\"Global_active_power\").agg(\n",
        "#     mean=(\"float_column\", \"mean\"),\n",
        "#     median=(\"float_column\", \"median\"),\n",
        "#     min=(\"float_column\", \"min\"),\n",
        "#     max=(\"float_column\", \"max\"),\n",
        "# )\n",
        "# data2 = grouped_data\n",
        "# data2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAkycSWrwgEZ"
      },
      "outputs": [],
      "source": [
        "#data2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIEX4l7S8hKy"
      },
      "outputs": [],
      "source": [
        "#print(\"\\nInformation about the dataframe:\")\n",
        "#print(data.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZWhcHhL8pY6"
      },
      "outputs": [],
      "source": [
        "#data['date_time'] = pd.to_datetime(data['Date'] + ' ' + data['Time']) #this is too slow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gl_X6iKqaroi"
      },
      "outputs": [],
      "source": [
        "#data2['date_time'] = pd.to_datetime(data2['Date'] + ' ' + data2['Time'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_jX83NBk0Ux"
      },
      "outputs": [],
      "source": [
        "#This block of code worked and saved on my drive\n",
        "# df = pd.DataFrame(data2)\n",
        "# df.to_csv('/content/drive/MyDrive/eta.csv')\n",
        "# df2 = pd.DataFrame(data)\n",
        "# df2.to_csv('/content/drive/MyDrive/etaysob.csv')\n",
        "#\n",
        "\n",
        " # Save without row index\n",
        "#df.to_csv('/content/drive/MyDrive/individual+household+electric+power+consumption/data_tab_delimited.csv', sep='\\t')\n",
        "#df.to_csv('/content/drive/MyDrive/individual+household+electric+power+consumption/my_data.csv', mode='a', header=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4N_6GMSmHA93"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.9.1 adabelief-tf==0.2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZ1wd95WlhF-"
      },
      "outputs": [],
      "source": [
        "data2 = pd.read_csv('/content/drive/MyDrive/ab.csv')\n",
        "data2 = data2.iloc[:, 1:]\n",
        "data = pd.read_csv('/content/drive/MyDrive/etaysob.csv')\n",
        "data = data.iloc[:, 1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cN9C0MGnlqC1"
      },
      "outputs": [],
      "source": [
        "# if data2.shape == data3.shape and all(data2 == data3):\n",
        "#     print(\"DataFrames are equal.\")\n",
        "# else:\n",
        "#     print(\"DataFrames are not equal.\")\n",
        "# df_diff = data2.compare(data3)\n",
        "# print(df_diff)\n",
        "print(data2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cz7-_ARLpDNx"
      },
      "outputs": [],
      "source": [
        "print(data.shape)\n",
        "print(data2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdQbL4StAgXr"
      },
      "outputs": [],
      "source": [
        "data['Global_active_power'] = pd.to_numeric(data['Global_active_power'], errors='coerce')\n",
        "data2['Global_active_power'] = pd.to_numeric(data2['Global_active_power'], errors='coerce')\n",
        "data = data.dropna(subset=['Global_active_power'])\n",
        "data2 = data2.dropna(subset=['Global_active_power'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMkxfmEh_Suq"
      },
      "outputs": [],
      "source": [
        "data['date_time'] = pd.to_datetime(data['date_time'])\n",
        "\n",
        "data2['date_time'] = pd.to_datetime(data2['date_time'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2G3yGo73Y7B4"
      },
      "outputs": [],
      "source": [
        "11111"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBr7uGHTAwrU"
      },
      "outputs": [],
      "source": [
        "data['year'] = data['date_time'].apply(lambda x: x.year)\n",
        "data['quarter'] = data['date_time'].apply(lambda x: x.quarter)\n",
        "data['month'] = data['date_time'].apply(lambda x: x.month)\n",
        "data['day'] = data['date_time'].apply(lambda x: x.day)\n",
        "data['hour'] = data['date_time'].apply(lambda x: x.hour)\n",
        "\n",
        "data2['year'] = data2['date_time'].apply(lambda x: x.year)\n",
        "data2['quarter'] = data2['date_time'].apply(lambda x: x.quarter)\n",
        "data2['month'] = data2['date_time'].apply(lambda x: x.month)\n",
        "data2['day'] = data2['date_time'].apply(lambda x: x.day)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YJuM_3P3-2_"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4P77vBeaBc-F"
      },
      "outputs": [],
      "source": [
        "data = data.loc[:,['date_time','Global_active_power', 'year','quarter','month','day','hour']]\n",
        "data2 = data2.loc[:,['date_time','Global_active_power', 'year','quarter','month','day']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTBa2W7tBkaa"
      },
      "outputs": [],
      "source": [
        "data.sort_values('date_time', inplace=True, ascending=True)\n",
        "data2.sort_values('date_time', inplace=True, ascending=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GLw57LyCqW7"
      },
      "outputs": [],
      "source": [
        "data = data.reset_index(drop=True)\n",
        "data2 = data2.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7t0ijTQCuwP"
      },
      "outputs": [],
      "source": [
        "data['weekday'] = data['date_time'].apply(lambda x: x.weekday() < 5).astype(int)\n",
        "data2['weekday'] = data2['date_time'].apply(lambda x: x.weekday() < 5).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFSNpbb1C00e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "fc981ff2-dc4a-40ff-a90f-1c6a68de9b1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows and columns: (2049280, 8)\n",
            "Minimum date_time: 2006-12-16 17:24:00\n",
            "Maximum date_time: 2010-12-11 23:59:00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  date_time  Global_active_power  year  quarter  month  day  \\\n",
              "2049275 2010-12-11 23:55:00               0.6900  2010        4     12   11   \n",
              "2049276 2010-12-11 23:56:00               0.6880  2010        4     12   11   \n",
              "2049277 2010-12-11 23:57:00               0.6880  2010        4     12   11   \n",
              "2049278 2010-12-11 23:58:00               0.6880  2010        4     12   11   \n",
              "2049279 2010-12-11 23:59:00               0.6880  2010        4     12   11   \n",
              "\n",
              "         hour  weekday  \n",
              "2049275    23        0  \n",
              "2049276    23        0  \n",
              "2049277    23        0  \n",
              "2049278    23        0  \n",
              "2049279    23        0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b4a5c06-4395-475a-9958-003c0e868888\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date_time</th>\n",
              "      <th>Global_active_power</th>\n",
              "      <th>year</th>\n",
              "      <th>quarter</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>hour</th>\n",
              "      <th>weekday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2049275</th>\n",
              "      <td>2010-12-11 23:55:00</td>\n",
              "      <td>0.6900</td>\n",
              "      <td>2010</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2049276</th>\n",
              "      <td>2010-12-11 23:56:00</td>\n",
              "      <td>0.6880</td>\n",
              "      <td>2010</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2049277</th>\n",
              "      <td>2010-12-11 23:57:00</td>\n",
              "      <td>0.6880</td>\n",
              "      <td>2010</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2049278</th>\n",
              "      <td>2010-12-11 23:58:00</td>\n",
              "      <td>0.6880</td>\n",
              "      <td>2010</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2049279</th>\n",
              "      <td>2010-12-11 23:59:00</td>\n",
              "      <td>0.6880</td>\n",
              "      <td>2010</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b4a5c06-4395-475a-9958-003c0e868888')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5b4a5c06-4395-475a-9958-003c0e868888 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5b4a5c06-4395-475a-9958-003c0e868888');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fe157b75-1ad7-46f4-894f-1d4f02853d40\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fe157b75-1ad7-46f4-894f-1d4f02853d40')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fe157b75-1ad7-46f4-894f-1d4f02853d40 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"date_time\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2010-12-11 23:55:00\",\n        \"max\": \"2010-12-11 23:59:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2010-12-11 23:56:00\",\n          \"2010-12-11 23:59:00\",\n          \"2010-12-11 23:57:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Global_active_power\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0008944271909999166,\n        \"min\": 0.688,\n        \"max\": 0.69,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.688,\n          0.69\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2010,\n        \"max\": 2010,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2010\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"quarter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 4,\n        \"max\": 4,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 12,\n        \"max\": 12,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 11,\n        \"max\": 11,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hour\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 23,\n        \"max\": 23,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          23\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weekday\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "print('Number of rows and columns:', data.shape)\n",
        "\n",
        "# Print the minimum and maximum date_time values\n",
        "print('Minimum date_time:', data.date_time.min())\n",
        "print('Maximum date_time:', data.date_time.max())\n",
        "\n",
        "# Display the last 5 rows of the data\n",
        "data.tail(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzFo68P4DxPF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "336043ef-0051-408d-8210-e54ae0f049e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statistics=724881.795, p=0.000\n",
            "Data does not look Gaussian (reject H0)\n"
          ]
        }
      ],
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "# Calculate the test statistics and p-value\n",
        "stat, p = stats.normaltest(data.Global_active_power)\n",
        "\n",
        "# Print the results\n",
        "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
        "\n",
        "# Set the significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Make a decision on the test result\n",
        "if p > alpha:\n",
        "    print('Data looks Gaussian (fail to reject H0)')\n",
        "else:\n",
        "    print('Data does not look Gaussian (reject H0)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fHEUooMD3FM"
      },
      "outputs": [],
      "source": [
        "sns.distplot(data.Global_active_power,color='purple')\n",
        "print( 'Kurtosis of normal distribution: {}'.format(stats.kurtosis(data.Global_active_power)))\n",
        "print( 'Skewness of normal distribution: {}'.format(stats.skew(data.Global_active_power)))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OE8QAazpVEMl"
      },
      "outputs": [],
      "source": [
        "sns.distplot(data2.Global_active_power,color='blue')\n",
        "print( 'Kurtosis of normal distribution: {}'.format(stats.kurtosis(data2.Global_active_power)))\n",
        "print( 'Skewness of normal distribution: {}'.format(stats.skew(data2.Global_active_power)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EiPxLHZVnCC"
      },
      "outputs": [],
      "source": [
        "print(data2.Global_active_power)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQ3h4kwTVyi3"
      },
      "outputs": [],
      "source": [
        "print(data.Global_active_power)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OT6CPSxXD_3k"
      },
      "outputs": [],
      "source": [
        "data1 = data[(data.date_time >= '2010-07-01') & (data.date_time < '2010-7-16')]\n",
        "\n",
        "# plt.figure(figsize=(14,6))\n",
        "# plt.plot(data1.date_time, data1.Global_active_power, color='purple')\n",
        "# plt.ylabel('Global Active Power (kW)', fontsize=12)\n",
        "# plt.xlabel('Date', fontsize=12)\n",
        "# plt.title('Active Power Consumption for a Particular Time Frame', fontsize=14)\n",
        "# plt.tight_layout()\n",
        "# plt.grid(True)\n",
        "# sns.despine(bottom=True, left=True)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyBYLcNLdcVl"
      },
      "outputs": [],
      "source": [
        "data1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2t6SnNeWbVy"
      },
      "outputs": [],
      "source": [
        "data3 = data2[(data2.date_time >= '2010-07-01') & (data2.date_time < '2010-7-16')]\n",
        "\n",
        "# plt.figure(figsize=(14,6))\n",
        "# plt.plot(data3.date_time, data3.Global_active_power, color='blue')\n",
        "# plt.ylabel('Global Active Power (kW)', fontsize=12)\n",
        "# plt.xlabel('Date', fontsize=12)\n",
        "# plt.title('Active Power Consumption for a Particular Time Frame', fontsize=14)\n",
        "# plt.tight_layout()\n",
        "# plt.grid(True)\n",
        "# sns.despine(bottom=True, left=True)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4Wx632-dSEs"
      },
      "outputs": [],
      "source": [
        "data3.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CCeaZfKJa6w"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "\n",
        "# # Create a figure with 2 subplots\n",
        "# plt.figure(figsize=(12,5))\n",
        "\n",
        "# # Plot the first subplot showing the violinplot of yearly global active power\n",
        "# plt.subplot(1,2,1)\n",
        "# # Adjust the subplot's width\n",
        "# plt.subplots_adjust(wspace=0.2)\n",
        "# # Create the violinplot using Seaborn's violinplot function\n",
        "# sns.violinplot(x=\"year\", y=\"Global_active_power\", data=data, color='purple')\n",
        "# # Label the x-axis\n",
        "# plt.xlabel('Year', fontsize=12)\n",
        "# # Add a title to the plot\n",
        "# plt.title('Violin plot of Yearly Global Active Power', fontsize=14)\n",
        "# # Remove the top and right spines of the plot\n",
        "# sns.despine(left=True, bottom=True)\n",
        "# # Add a tight layout to the plot\n",
        "# plt.tight_layout()\n",
        "\n",
        "# # Plot the second subplot showing the violinplot of quarterly global active power\n",
        "# plt.subplot(1,2,2)\n",
        "# # Create the violinplot using Seaborn's violinplot function\n",
        "# sns.violinplot(x=\"quarter\", y=\"Global_active_power\", data=data, color='purple')\n",
        "# # Label the x-axis\n",
        "# plt.xlabel('Quarter', fontsize=12)\n",
        "# # Add a title to the plot\n",
        "# plt.title('Violin plot of Quarterly Global Active Power', fontsize=14)\n",
        "# # Remove the top and right spines of the plot\n",
        "# sns.despine(left=True, bottom=True)\n",
        "# # Add a tight layout to the plot\n",
        "# plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSFw42o4ZpN8"
      },
      "outputs": [],
      "source": [
        "# plt.figure(figsize=(12,5))\n",
        "\n",
        "# # Plot the first subplot showing the violinplot of yearly global active power\n",
        "# plt.subplot(1,2,1)\n",
        "# # Adjust the subplot's width\n",
        "# plt.subplots_adjust(wspace=0.2)\n",
        "# # Create the violinplot using Seaborn's violinplot function\n",
        "# sns.violinplot(x=\"year\", y=\"Global_active_power\", data=data2, color='blue')\n",
        "# # Label the x-axis\n",
        "# plt.xlabel('Year', fontsize=12)\n",
        "# # Add a title to the plot\n",
        "# plt.title('Violin plot of Yearly Global Active Power', fontsize=14)\n",
        "# # Remove the top and right spines of the plot\n",
        "# sns.despine(left=True, bottom=True)\n",
        "# # Add a tight layout to the plot\n",
        "# plt.tight_layout()\n",
        "\n",
        "# # Plot the second subplot showing the violinplot of quarterly global active power\n",
        "# plt.subplot(1,2,2)\n",
        "# # Create the violinplot using Seaborn's violinplot function\n",
        "# sns.violinplot(x=\"quarter\", y=\"Global_active_power\", data=data2, color='blue')\n",
        "# # Label the x-axis\n",
        "# plt.xlabel('Quarter', fontsize=12)\n",
        "# # Add a title to the plot\n",
        "# plt.title('Violin plot of Quarterly Global Active Power', fontsize=14)\n",
        "# # Remove the top and right spines of the plot\n",
        "# sns.despine(left=True, bottom=True)\n",
        "# # Add a tight layout to the plot\n",
        "# plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sDk2TAjJq0x"
      },
      "outputs": [],
      "source": [
        "# Plotting the histogram and normal probability plot for 'Global_active_power' column\n",
        "plt.figure(figsize=(15,7))\n",
        "\n",
        "# Histogram of 'Global_active_power' column\n",
        "plt.subplot(1,2,1)\n",
        "data1['Global_active_power'].hist(bins=70, color='purple')\n",
        "plt.title('Global Active Power Distribution', fontsize=16)\n",
        "\n",
        "# Normal Probability Plot of 'Global_active_power' column\n",
        "# Normal Probability Plot of 'Global_active_power' column\n",
        "plt.subplot(1,2,2)\n",
        "# Create the normal probability plot using stats.probplot\n",
        "stats.probplot(data1['Global_active_power'], plot=plt, fit=True, rvalue=True)\n",
        "# Change the color of the data points\n",
        "plt.gca().get_lines()[0].set_color('green')  # Set the color of the data points to green\n",
        "# Add a line to the plot\n",
        "plt.plot([0, max(data1['Global_active_power'])], [0, max(data1['Global_active_power'])], color='purple', linestyle='--')\n",
        "plt.title('Normal Probability Plot of Global Active Power', fontsize=14)\n",
        "\n",
        "\n",
        "# Printing the summary statistics of 'Global_active_power' column\n",
        "print(data1.describe().T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bOjMAZJaGUu"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,7))\n",
        "\n",
        "# Histogram of 'Global_active_power' column\n",
        "plt.subplot(1,2,1)\n",
        "data3['Global_active_power'].hist(bins=70, color='blue')\n",
        "plt.title('Global Active Power Distribution', fontsize=16)\n",
        "\n",
        "# Normal Probability Plot of 'Global_active_power' column\n",
        "plt.subplot(1,2,2)\n",
        "# Create the normal probability plot using stats.probplot\n",
        "stats.probplot(data3['Global_active_power'], plot=plt, fit=True, rvalue=True)\n",
        "# Add a line to the plot\n",
        "plt.plot([0, max(data1['Global_active_power'])], [0, max(data3['Global_active_power'])], color='blue', linestyle='--')\n",
        "plt.title('Normal Probability Plot of Global Active Power', fontsize=14)\n",
        "\n",
        "\n",
        "# Printing the summary statistics of 'Global_active_power' column\n",
        "print(data3.describe().T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCSXQrdeji7Z"
      },
      "outputs": [],
      "source": [
        "data1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1R8skDcJyH_"
      },
      "outputs": [],
      "source": [
        "data1=data.loc[:,['date_time','Global_active_power']]\n",
        "data1.set_index('date_time',inplace=True)\n",
        "\n",
        "data4=data2.loc[:,['date_time','Global_active_power']]\n",
        "data4.set_index('date_time',inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZ6C1ZESbzK1"
      },
      "outputs": [],
      "source": [
        "# Assuming 'data1' has a datetime index (adjust if necessary)\n",
        "\n",
        "# Select the desired day (replace with the actual date)\n",
        "desired_day = '2010-07-02'\n",
        "daily_data = data1[data1.index.date == desired_day]\n",
        "\n",
        "# Resample by hour and calculate the mean for each hour\n",
        "hourly_mean = daily_data['Global_active_power'].resample('H').mean()\n",
        "\n",
        "# Create a color list for each hour (you can customize the colors)\n",
        "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k'] * 4  # Repeat 4 times for 24 hours\n",
        "\n",
        "# Create the plot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
        "for i, hour in enumerate(hourly_mean.index.hour):\n",
        "  plt.plot(hourly_mean.index[hourly_mean.index.hour == hour], hourly_mean[hourly_mean.index.hour == hour], marker='o', linestyle='-', label=f'{hour} Hour', color=colors[i])\n",
        "\n",
        "# Set labels and title\n",
        "plt.xlabel('Time of Day')\n",
        "plt.ylabel('Mean Global Active Power')\n",
        "plt.title(f'Mean Global Active Power by Hour for {desired_day}')\n",
        "plt.legend(title='Hour of Day')\n",
        "\n",
        "# Rotate x-axis labels for better readability (optional)\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Show the plot\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnD28u9uJ78J"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(22,20))\n",
        "# Adjust the subplot spacing\n",
        "fig.subplots_adjust(hspace=1)\n",
        "\n",
        "# Create first subplot\n",
        "ax1 = fig.add_subplot(5,1,1)\n",
        "# Plot the resampled mean of Global_active_power over day with different color\n",
        "ax1.plot(data1['Global_active_power'].resample('D').mean(), linewidth=1, color='green')\n",
        "# Set the title for the subplot\n",
        "ax1.set_title('Mean Global active power resampled over day')\n",
        "# Set major tick parameters for the subplot\n",
        "ax1.tick_params(axis='both', which='major')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create second subplot\n",
        "ax2 = fig.add_subplot(5,1,2, sharex=ax1)\n",
        "# Plot the resampled mean of Global_active_power over week with different color\n",
        "ax2.plot(data1['Global_active_power'].resample('W').mean(), linewidth=1, color='green')\n",
        "# Set the title for the subplot\n",
        "ax2.set_title('Mean Global active power resampled over week')\n",
        "# Set major tick parameters for the subplot\n",
        "ax2.tick_params(axis='both', which='major')\n",
        "\n",
        "# Create third subplot\n",
        "ax3 = fig.add_subplot(5,1,3, sharex=ax1)\n",
        "# Plot the resampled mean of Global_active_power over month with different color\n",
        "ax3.plot(data1['Global_active_power'].resample('M').mean(), linewidth=1, color='green')\n",
        "# Set the title for the subplot\n",
        "ax3.set_title('Mean Global active power resampled over month')\n",
        "# Set major tick parameters for the subplot\n",
        "ax3.tick_params(axis='both', which='major')\n",
        "\n",
        "# Create third subplot\n",
        "ax4  = fig.add_subplot(5,1,4, sharex=ax1)\n",
        "# Plot the resampled mean of Global_active_power over month with different color\n",
        "ax4.plot(data1['Global_active_power'].resample('Q').mean(),linewidth=1, color='green')\n",
        "# Set the title for the subplot\n",
        "ax4.set_title('Mean Global active power resampled over quarter')\n",
        "# Set major tick parameters for the subplot\n",
        "ax4.tick_params(axis='both', which='major')\n",
        "\n",
        "\n",
        "# Create third subplot\n",
        "ax5  = fig.add_subplot(5,1,5, sharex=ax1)\n",
        "# Plot the resampled mean of Global_active_power over month with different color\n",
        "ax5.plot(data1['Global_active_power'].resample('A').mean(),linewidth=1, color='green')\n",
        "# Set the title for the subplot\n",
        "ax5.set_title('Mean Global active power resampled over year')\n",
        "# Set major tick parameters for the subplot\n",
        "ax5.tick_params(axis='both', which='major')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fp12YPyku4tc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mb1eGx6zawRS"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(22,20))\n",
        "# Adjust the subplot spacing\n",
        "fig.subplots_adjust(hspace=1)\n",
        "\n",
        "# Create first subplot\n",
        "ax1 = fig.add_subplot(5,1,1)\n",
        "# Plot the resampled mean of Global_active_power over day with different color\n",
        "ax1.plot(data4['Global_active_power'].resample('D').mean(), linewidth=1, color='blue')\n",
        "# Set the title for the subplot\n",
        "ax1.set_title('Mean Global active power resampled over day')\n",
        "# Set major tick parameters for the subplot\n",
        "ax1.tick_params(axis='both', which='major')\n",
        "\n",
        "# Create second subplot\n",
        "ax2 = fig.add_subplot(5,1,2, sharex=ax1)\n",
        "# Plot the resampled mean of Global_active_power over week with different color\n",
        "ax2.plot(data4['Global_active_power'].resample('W').mean(), linewidth=1, color='blue')\n",
        "# Set the title for the subplot\n",
        "ax2.set_title('Mean Global active power resampled over week')\n",
        "# Set major tick parameters for the subplot\n",
        "ax2.tick_params(axis='both', which='major')\n",
        "\n",
        "# Create third subplot\n",
        "ax3 = fig.add_subplot(5,1,3, sharex=ax1)\n",
        "# Plot the resampled mean of Global_active_power over month with different color\n",
        "ax3.plot(data4['Global_active_power'].resample('M').mean(), linewidth=1, color='blue')\n",
        "# Set the title for the subplot\n",
        "ax3.set_title('Mean Global active power resampled over month')\n",
        "# Set major tick parameters for the subplot\n",
        "ax3.tick_params(axis='both', which='major')\n",
        "\n",
        "# Create third subplot\n",
        "ax4  = fig.add_subplot(5,1,4, sharex=ax1)\n",
        "# Plot the resampled mean of Global_active_power over month with different color\n",
        "ax4.plot(data4['Global_active_power'].resample('Q').mean(),linewidth=1, color='blue')\n",
        "# Set the title for the subplot\n",
        "ax4.set_title('Mean Global active power resampled over quarter')\n",
        "# Set major tick parameters for the subplot\n",
        "ax4.tick_params(axis='both', which='major')\n",
        "\n",
        "\n",
        "# Create third subplot\n",
        "ax5  = fig.add_subplot(5,1,5, sharex=ax1)\n",
        "# Plot the resampled mean of Global_active_power over month with different color\n",
        "ax5.plot(data4['Global_active_power'].resample('A').mean(),linewidth=1, color='blue')\n",
        "# Set the title for the subplot\n",
        "ax5.set_title('Mean Global active power resampled over year')\n",
        "# Set major tick parameters for the subplot\n",
        "ax5.tick_params(axis='both', which='major')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZgCwY_hJ_7c"
      },
      "outputs": [],
      "source": [
        "# Import the matplotlib library for plotting graphs\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a figure with 2 rows and 2 columns and set its size to 14x8\n",
        "plt.figure(figsize=(16,10))\n",
        "\n",
        "# First subplot in the first row, first column\n",
        "plt.subplot(2,2,1)\n",
        "# Group data by year and take the mean of the 'Global_active_power' column\n",
        "grouped_by_year = data.groupby('year').Global_active_power.agg('mean')\n",
        "# Plot the mean of 'Global_active_power' by year with red color\n",
        "grouped_by_year.plot(color='purple')\n",
        "# Set the x label to be empty\n",
        "plt.xlabel('')\n",
        "# Set the title to 'Average Global Active Power by Year' with font size 12 and font weight 'bold'\n",
        "plt.title('Average Global Active Power by Year', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Second subplot in the first row, second column\n",
        "plt.subplot(2,2,2)\n",
        "# Group data by quarter and take the mean of the 'Global_active_power' column\n",
        "grouped_by_quarter = data.groupby('quarter').Global_active_power.agg('mean')\n",
        "# Plot the mean of 'Global_active_power' by quarter with blue color\n",
        "grouped_by_quarter.plot(color='purple')\n",
        "# Set the x label to be empty\n",
        "plt.xlabel('')\n",
        "# Set the title to 'Average Global Active Power by Quarter' with font size 12 and font weight 'bold'\n",
        "plt.title('Average Global Active Power by Quarter', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Third subplot in the second row, first column\n",
        "plt.subplot(2,2,3)\n",
        "# Group data by month and take the mean of the 'Global_active_power' column\n",
        "grouped_by_month = data.groupby('month').Global_active_power.agg('mean')\n",
        "# Plot the mean of 'Global_active_power' by month with purple color\n",
        "grouped_by_month.plot(color='purple')\n",
        "# Set the x label to be empty\n",
        "plt.xlabel('')\n",
        "# Set the title to 'Average Global Active Power by Month' with font size 12 and font weight 'bold'\n",
        "plt.title('Average Global Active Power by Month', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Fourth subplot in the second row, second column\n",
        "plt.subplot(2,2,4)\n",
        "# Group data by day and take the mean of the 'Global_active_power' column\n",
        "grouped_by_day = data.groupby('day').Global_active_power.agg('mean')\n",
        "# Plot the mean of 'Global_active_power' by day with green color\n",
        "grouped_by_day.plot(color='purple')\n",
        "# Set the x label to be empty\n",
        "plt.xlabel('')\n",
        "# Set the title to 'Average Global Active Power by Day' with font size 12 and font weight 'bold'\n",
        "plt.title('Average Global Active Power by Day', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Use tight_layout to adjust the subplots so that they fit into the figure area\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FOgIwPmiQca"
      },
      "outputs": [],
      "source": [
        "# Import the matplotlib library for plotting graphs\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a figure with 2 rows and 2 columns and set its size to 14x8\n",
        "plt.figure(figsize=(16,10))\n",
        "\n",
        "# First subplot in the first row, first column\n",
        "plt.subplot(2,2,1)\n",
        "# Group data by year and take the mean of the 'Global_active_power' column\n",
        "grouped_by_year = data2.groupby('year').Global_active_power.agg('mean')\n",
        "# Plot the mean of 'Global_active_power' by year with red color\n",
        "grouped_by_year.plot(color='blue')\n",
        "# Set the x label to be empty\n",
        "plt.xlabel('')\n",
        "# Set the title to 'Average Global Active Power by Year' with font size 12 and font weight 'bold'\n",
        "plt.title('Average Global Active Power by Year', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Second subplot in the first row, second column\n",
        "plt.subplot(2,2,2)\n",
        "# Group data by quarter and take the mean of the 'Global_active_power' column\n",
        "grouped_by_quarter = data2.groupby('quarter').Global_active_power.agg('mean')\n",
        "# Plot the mean of 'Global_active_power' by quarter with blue color\n",
        "grouped_by_quarter.plot(color='blue')\n",
        "# Set the x label to be empty\n",
        "plt.xlabel('')\n",
        "# Set the title to 'Average Global Active Power by Quarter' with font size 12 and font weight 'bold'\n",
        "plt.title('Average Global Active Power by Quarter', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Third subplot in the second row, first column\n",
        "plt.subplot(2,2,3)\n",
        "# Group data by month and take the mean of the 'Global_active_power' column\n",
        "grouped_by_month = data2.groupby('month').Global_active_power.agg('mean')\n",
        "# Plot the mean of 'Global_active_power' by month with purple color\n",
        "grouped_by_month.plot(color='blue')\n",
        "# Set the x label to be empty\n",
        "plt.xlabel('')\n",
        "# Set the title to 'Average Global Active Power by Month' with font size 12 and font weight 'bold'\n",
        "plt.title('Average Global Active Power by Month', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Fourth subplot in the second row, second column\n",
        "plt.subplot(2,2,4)\n",
        "# Group data by day and take the mean of the 'Global_active_power' column\n",
        "grouped_by_day = data2.groupby('day').Global_active_power.agg('mean')\n",
        "# Plot the mean of 'Global_active_power' by day with green color\n",
        "grouped_by_day.plot(color='blue')\n",
        "# Set the x label to be empty\n",
        "plt.xlabel('')\n",
        "# Set the title to 'Average Global Active Power by Day' with font size 12 and font weight 'bold'\n",
        "plt.title('Average Global Active Power by Day', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Use tight_layout to adjust the subplots so that they fit into the figure area\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87RQUQFsOI9w"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from matplotlib import pyplot\n",
        "from statsmodels.tsa.stattools import adfuller"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOQKFspNSm4V"
      },
      "outputs": [],
      "source": [
        "def test_stationarity(timeseries):\n",
        "    # Calculate rolling mean and standard deviation\n",
        "    rolmean = timeseries.rolling(window=30).mean()\n",
        "    rolstd = timeseries.rolling(window=30).std()\n",
        "\n",
        "    # Plot original timeseries, rolling mean, and rolling standard deviation\n",
        "    plt.figure(figsize=(20,5))\n",
        "    sns.despine(left=True)\n",
        "    orig = plt.plot(timeseries, color='pink',label='Original')\n",
        "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
        "    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
        "\n",
        "    # Add legend\n",
        "    plt.legend(loc='best')\n",
        "    # Add title\n",
        "    plt.title('Rolling Mean & Standard Deviation of Global Active Power')\n",
        "    plt.show()\n",
        "\n",
        "    # Perform and display results of Dickey-Fuller test\n",
        "    print ('<Results of Dickey-Fuller Test>')\n",
        "    dftest = adfuller(timeseries, autolag='AIC')\n",
        "    dfoutput = pd.Series(dftest[0:4],\n",
        "                     index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
        "    for key,value in dftest[4].items():\n",
        "        dfoutput['Critical Value (%s)'%key] = value\n",
        "    print(dfoutput)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpOUgggl0u6y"
      },
      "outputs": [],
      "source": [
        "# Assuming test_stationarity() is a custom function to test stationarity\n",
        "test_stationarity(data2['Global_active_power'].dropna().head(800))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4h2hkdYhK-7A"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def remove_outliers(df, date_time):\n",
        "    # Calculate the first quartile (Q1) and third quartile (Q3)\n",
        "    Q1 = df['date_time'].quantile(0.25)\n",
        "    Q3 = df['date_time'].quantile(0.75)\n",
        "\n",
        "    # Calculate the interquartile range (IQR)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    # Define the lower and upper bounds for outliers detection\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    # Remove rows where the column value is an outlier\n",
        "    cleaned_df = df[(df['date_time'] >= lower_bound) & (df['date_time'] <= upper_bound)]\n",
        "\n",
        "    return cleaned_df\n",
        "\n",
        "# Example usage:\n",
        "# Sample DataFrame (replace this with your own DataFrame)\n",
        "\n",
        "\n",
        "# Remove rows with outliers in column 'B'\n",
        "df = pd.DataFrame(data)\n",
        "cleaned_df = remove_outliers(df, 'date_time')\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "print(\"\\nCleaned DataFrame (without rows containing outliers in column 'B'):\")\n",
        "print(cleaned_df.head(40))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DHvTAvEnomB"
      },
      "source": [
        "# lstm for sampled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEnQagkn_N7k"
      },
      "outputs": [],
      "source": [
        "#Transform the Global_active_power column of the data DataFrame into a numpy array of float values\n",
        "\n",
        "dataset = data2.Global_active_power.values.astype('float32')\n",
        "#Reshape the numpy array into a 2D array with 1 column\n",
        "\n",
        "dataset = np.reshape(dataset, (-1, 1))\n",
        "#Create an instance of the MinMaxScaler class to scale the values between 0 and 1\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "#Fit the MinMaxScaler to the transformed data and transform the values\n",
        "\n",
        "dataset = scaler.fit_transform(dataset)\n",
        "#Split the transformed data into a training set (80%) and a test set (20%)\n",
        "\n",
        "train_size = int(len(dataset) * 0.80)\n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDPENGdcMSXI"
      },
      "outputs": [],
      "source": [
        "col_dates = data.date_time.values\n",
        "col_dates = np.reshape(col_dates, (-1, 1))\n",
        "date_train, date_test = col_dates[0:train_size, :], col_dates[train_size:len(dataset), :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8pIEUzj_fGu"
      },
      "outputs": [],
      "source": [
        "def create_dataset(dataset, dates, look_back=1):\n",
        "    X, Y = [], []\n",
        "    d = []\n",
        "    for i in range(len(dataset)-look_back-1):\n",
        "        a = dataset[i:(i+look_back), 0]\n",
        "        X.append(a)\n",
        "        Y.append(dataset[i + look_back, 0])\n",
        "        d.append(dates[i + look_back, 0])\n",
        "    return np.array(X), np.array(Y), np.array(d)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "look_back = 30\n",
        "X_trainr, Y_trainr, d_trainr = create_dataset(train, date_train, look_back)\n",
        "X_testr, Y_testr, d_testr = create_dataset(test, date_test, look_back)"
      ],
      "metadata": {
        "id": "zNZGoT74hCMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "look_back = 30\n",
        "X_train8, Y_train8, d_train8 = create_dataset(train, date_train, look_back)\n",
        "X_test8, Y_test8, d_test8 = create_dataset(test, date_test, look_back)"
      ],
      "metadata": {
        "id": "iPPsnlz20oYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "look_back = 30\n",
        "X_train, Y_train, d_train = create_dataset(train, date_train, look_back)\n",
        "X_test, Y_test, d_test = create_dataset(test, date_test, look_back)"
      ],
      "metadata": {
        "id": "WM54Ev5PlxVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZHivLcV_kir"
      },
      "outputs": [],
      "source": [
        "look_back = 30\n",
        "X_train, Y_train, d_train = create_dataset(train, date_train, look_back)\n",
        "X_test, Y_test, d_test = create_dataset(test, date_test, look_back)\n",
        "\n",
        "X_train2, Y_train2, d_train2 = create_dataset(train, date_train, look_back)\n",
        "X_test2, Y_test2, d_test2 = create_dataset(test, date_test, look_back)\n",
        "\n",
        "X_train3, Y_train3, d_train3 = X_train, Y_train, d_train\n",
        "X_test3, Y_test3, d_test3 = X_test, Y_test, d_test\n",
        "\n",
        "X_train4, Y_train4, d_train4 = X_train, Y_train, d_train\n",
        "# X_val4, Y_val4, d_val4 = X_val, Y_val, d_val\n",
        "X_test4, Y_test4, d_test4 = X_test, Y_test, d_test\n",
        "\n",
        "X_train5, Y_train5, d_train5 = X_train, Y_train, d_train\n",
        "X_test5, Y_test5, d_test5 = X_test, Y_test, d_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xVRbLy6_ubO"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuuOGHvm_yT9"
      },
      "outputs": [],
      "source": [
        "Y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MqVlbaG_0ZL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "680cebbb-d94c-41ea-8023-172faf44ce51"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(79961, 1, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-26pj7dUyDmf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eacb330-d722-4d34-c60f-5a4e31d39c06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(79961, 1, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "X_train2 = np.reshape(X_train2, (X_train2.shape[0], 1, X_train2.shape[1]))\n",
        "X_test2 = np.reshape(X_test2, (X_test2.shape[0], 1, X_test2.shape[1]))\n",
        "X_train2.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYWlhfDWePzc"
      },
      "outputs": [],
      "source": [
        "X_train3 = np.reshape(X_train3, (X_train3.shape[0], 1, X_train3.shape[1]))\n",
        "X_test3 = np.reshape(X_test3, (X_test3.shape[0], 1, X_test3.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANfdTUAL_8H7"
      },
      "outputs": [],
      "source": [
        "X_train4 = np.reshape(X_train4, (X_train4.shape[0], 1, X_train4.shape[1]))\n",
        "# X_val4 = np.reshape(X_val4, (X_val4.shape[0], 1, X_val4.shape[1]))\n",
        "X_test4 = np.reshape(X_test4, (X_test4.shape[0], 1, X_test4.shape[1]))\n",
        "\n",
        "X_train5 = np.reshape(X_train5, (X_train5.shape[0], 1, X_train5.shape[1]))\n",
        "X_test5 = np.reshape(X_test5, (X_test5.shape[0], 1, X_test5.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvkIkXGsyZYa"
      },
      "outputs": [],
      "source": [
        "X_train8 = np.reshape(X_train8, (X_train8.shape[0], 1, X_train8.shape[1]))\n",
        "X_test8 = np.reshape(X_test8, (X_test8.shape[0], 1, X_test8.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1_B6RaN__rd"
      },
      "outputs": [],
      "source": [
        "# # Defining the LSTM model\n",
        "# model = Sequential()\n",
        "\n",
        "# # Adding the first layer with 100 LSTM units and input shape of the data\n",
        "# model.add(LSTM(100, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "\n",
        "# # Adding a dropout layer to avoid overfitting\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "# # Adding a dense layer with 1 unit to make predictions\n",
        "# model.add(Dense(1))\n",
        "\n",
        "# # Compiling the model with mean squared error as the loss function and using Adam optimizer\n",
        "# model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# # Fitting the model on training data and using early stopping to avoid overfitting\n",
        "# history1 = model.fit(X_train, Y_train, epochs=10, batch_size=1600, validation_data=(X_test, Y_test),\n",
        "#                     callbacks=[EarlyStopping(monitor='val_loss', patience=4)], verbose=1, shuffle=False)\n",
        "\n",
        "# # Displaying a summary of the model\n",
        "# model.summary()\n",
        "\n",
        "\n",
        "# from keras.callbacks import EarlyStopping\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import LSTM, Dense\n",
        "# from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# model = Sequential()\n",
        "\n",
        "# # Reduce number of units\n",
        "# model.add(LSTM(32, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "\n",
        "# # Remove Dropout temporarily (optional)\n",
        "# # model.add(Dropout(0.2))\n",
        "\n",
        "# # Add L2 regularization\n",
        "# model.add(Dense(1, kernel_regularizer=l2(0.01)))\n",
        "\n",
        "# # Compile and fit (rest remains same)\n",
        "# model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "# history = model.fit(X_train, Y_train, epochs=10, batch_size=3200, validation_data=(X_test, Y_test),\n",
        "#                     callbacks=[EarlyStopping(monitor='val_loss', patience=4)], verbose=1, shuffle=False)\n",
        "\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "model1 = Sequential()\n",
        "\n",
        "# Reduce number of units in Bi-LSTM layers\n",
        "model1.add(Bidirectional(LSTM(64, return_sequences=True), input_shape=(X_train2.shape[1], X_train2.shape[2])))\n",
        "\n",
        "# Remove Dropout temporarily\n",
        "\n",
        "model1.add(Bidirectional(LSTM(64)))\n",
        "\n",
        "# Add L2 regularization to Dense layer\n",
        "model1.add(Dense(1, kernel_regularizer=l2(0.001)))\n",
        "\n",
        "# Compile and fit (rest remains same)\n",
        "model1.compile(loss='mean_squared_error', optimizer='adam')\n",
        "history2 = model1.fit(X_train2, Y_train2, epochs=10, batch_size=1600, validation_data=(X_test2, Y_test2),\n",
        "                    callbacks=[EarlyStopping(monitor='val_loss', patience=4)], verbose=1, shuffle=False)\n",
        "\n",
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWZNiJmdE-p8",
        "outputId": "396ad442-e190-4dae-a059-ab695bc0445e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "50/50 [==============================] - 18s 151ms/step - loss: 0.0126 - val_loss: 0.0062\n",
            "Epoch 2/10\n",
            "50/50 [==============================] - 3s 62ms/step - loss: 0.0057 - val_loss: 0.0041\n",
            "Epoch 3/10\n",
            "50/50 [==============================] - 3s 62ms/step - loss: 0.0045 - val_loss: 0.0034\n",
            "Epoch 4/10\n",
            "50/50 [==============================] - 3s 63ms/step - loss: 0.0038 - val_loss: 0.0029\n",
            "Epoch 5/10\n",
            "50/50 [==============================] - 5s 98ms/step - loss: 0.0034 - val_loss: 0.0025\n",
            "Epoch 6/10\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.0030 - val_loss: 0.0022\n",
            "Epoch 7/10\n",
            "50/50 [==============================] - 3s 62ms/step - loss: 0.0028 - val_loss: 0.0021\n",
            "Epoch 8/10\n",
            "50/50 [==============================] - 3s 62ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 9/10\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 10/10\n",
            "50/50 [==============================] - 5s 91ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional (Bidirectiona  (None, 1, 128)           48640     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 128)              98816     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 147,585\n",
            "Trainable params: 147,585\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9ByR1XIBOSE"
      },
      "outputs": [],
      "source": [
        "# train_predict = model.predict(X_train)\n",
        "# test_predict = model.predict(X_test)\n",
        "# # invert predictions\n",
        "# train_predict = scaler.inverse_transform(train_predict)\n",
        "# Y_train = scaler.inverse_transform([Y_train])\n",
        "# test_predict = scaler.inverse_transform(test_predict)\n",
        "# Y_test = scaler.inverse_transform([Y_test])\n",
        "\n",
        "# print('Train Mean Absolute Error:', mean_absolute_error(Y_train[0], train_predict[:,0]))\n",
        "# print('Train Root Mean Squared Error:',np.sqrt(mean_squared_error(Y_train[0], train_predict[:,0])))\n",
        "# print('Test Mean Absolute Error:', mean_absolute_error(Y_test[0], test_predict[:,0]))\n",
        "# print('Test Root Mean Squared Error:',np.sqrt(mean_squared_error(Y_test[0], test_predict[:,0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Et0WqLXpqL62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31f84e15-2a9f-4f9e-a446-68cd385f1fe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2499/2499 [==============================] - 8s 3ms/step\n",
            "624/624 [==============================] - 3s 4ms/step\n",
            "Train Mean Absolute Error: 0.19348862008805254\n",
            "Train Root Mean Squared Error: 0.40544151770477554\n",
            "Test Mean Absolute Error: 0.15228363015600171\n",
            "Test Root Mean Squared Error: 0.33722428929915305\n"
          ]
        }
      ],
      "source": [
        "train_predict1 = model1.predict(X_train2)\n",
        "test_predict1 = model1.predict(X_test2)\n",
        "# invert predictions\n",
        "train_predict1 = scaler.inverse_transform(train_predict1)\n",
        "Y_train2 = scaler.inverse_transform([Y_train2])\n",
        "test_predict1 = scaler.inverse_transform(test_predict1)\n",
        "Y_test2 = scaler.inverse_transform([Y_test2])\n",
        "\n",
        "print('Train Mean Absolute Error:', mean_absolute_error(Y_train2[0], train_predict1[:,0]))\n",
        "print('Train Root Mean Squared Error:',np.sqrt(mean_squared_error(Y_train2[0], train_predict1[:,0])))\n",
        "print('Test Mean Absolute Error:', mean_absolute_error(Y_test2[0], test_predict1[:,0]))\n",
        "print('Test Root Mean Squared Error:',np.sqrt(mean_squared_error(Y_test2[0], test_predict1[:,0])))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_bilstm=np.sqrt(mean_squared_error(Y_test2[0], test_predict1[:,0]))\n",
        "mae_bilstm=mean_absolute_error(Y_test2[0], test_predict1[:,0])"
      ],
      "metadata": {
        "id": "LhWYHYPhlsJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhgDi4_OxF0E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2a76948-fcfc-4dbc-a90a-f86c8d0611cc",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "313/313 [==============================] - 5s 7ms/step - loss: 0.0044 - val_loss: 0.0017\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0022 - val_loss: 0.0014\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0020 - val_loss: 0.0013\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0020 - val_loss: 0.0013\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0019 - val_loss: 0.0013\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0019 - val_loss: 0.0013\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0019 - val_loss: 0.0013\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0019 - val_loss: 0.0013\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru (GRU)                   (None, 64)                18432     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 18,497\n",
            "Trainable params: 18,497\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "624/624 [==============================] - 1s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# from tensorflow.keras.layers import GRU, Dropout, Dense\n",
        "\n",
        "# model3 = Sequential()\n",
        "\n",
        "# # Add the GRU layer with 100 units\n",
        "# model3.add(GRU(100, input_shape=(X_train3.shape[1], X_train3.shape[2])))\n",
        "\n",
        "# # Add dropout for regularization\n",
        "# model3.add(Dropout(0.2))\n",
        "\n",
        "# # Add the output layer\n",
        "# model3.add(Dense(1))\n",
        "\n",
        "# # Compile the model\n",
        "# model3.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# # Fit the model\n",
        "# history3 = model3.fit(X_train3, Y_train3, epochs=10, batch_size=1600, validation_data=(X_test3, Y_test3),\n",
        "#                     callbacks=[EarlyStopping(monitor='val_loss', patience=4)], verbose=1, shuffle=False)\n",
        "\n",
        "# # Display model summary\n",
        "# model3.summary()\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l1, l2  # Import both L1 and L2 for exploration\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define hyperparameters\n",
        "n_layers = 1\n",
        "n_units = 64\n",
        "learning_rate = 0.001\n",
        "dropout_rate = 0.2\n",
        "regularizer = l2(0.001)\n",
        "\n",
        "# Create the GRU model with hyperparameter flexibility\n",
        "def create_gru_model(input_shape, n_layers=1, n_units=64, learning_rate=0.001,\n",
        "                     dropout_rate=0, regularizer=None):\n",
        "\n",
        "\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  for _ in range(n_layers):\n",
        "    return_sequences = True if n_layers > 1 else False  # Adjust for stacked layers\n",
        "    model.add(GRU(n_units, activation='tanh', return_sequences=return_sequences, input_shape=input_shape))\n",
        "    if dropout_rate > 0:\n",
        "      model.add(Dropout(dropout_rate))  # Add dropout for regularization\n",
        "\n",
        "  # Add regularization to Dense layer\n",
        "  model.add(Dense(1, activation='linear', kernel_regularizer=regularizer))\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=learning_rate))\n",
        "\n",
        "  return model\n",
        "\n",
        "# Create the model with appropriate input shape\n",
        "model4 = create_gru_model(X_train3.shape[1:])\n",
        "\n",
        "# Early stopping callback to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=4)\n",
        "\n",
        "# Train the model (adjust epochs and batch size based on dataset size and hardware)\n",
        "history4 = model4.fit(X_train3, Y_train3, epochs=10, batch_size=256,  # May need more epochs\n",
        "                       validation_data=(X_test3, Y_test3), callbacks=[early_stopping], verbose=1, shuffle=False)\n",
        "\n",
        "# Print model summary\n",
        "model4.summary()\n",
        "\n",
        "# Make predictions (optional)\n",
        "predictions = model4.predict(X_test3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_lorzVF9mus",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcedfbba-4ec9-416f-9210-9230a89198ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2499/2499 [==============================] - 5s 2ms/step\n",
            "624/624 [==============================] - 1s 2ms/step\n",
            "Train Mean Absolute Error: 0.18647008898275405\n",
            "Train Root Mean Squared Error: 0.3972001640500711\n",
            "Test Mean Absolute Error: 0.14212249289668466\n",
            "Test Root Mean Squared Error: 0.32951438714603876\n"
          ]
        }
      ],
      "source": [
        "train_predict2 = model4.predict(X_train3)\n",
        "test_predict2 = model4.predict(X_test3)\n",
        "# invert predictions\n",
        "train_predict2 = scaler.inverse_transform(train_predict2)\n",
        "Y_train3 = scaler.inverse_transform([Y_train3])\n",
        "test_predict2 = scaler.inverse_transform(test_predict2)\n",
        "Y_test3 = scaler.inverse_transform([Y_test3])\n",
        "\n",
        "print('Train Mean Absolute Error:', mean_absolute_error(Y_train3[0], train_predict2[:,0]))\n",
        "print('Train Root Mean Squared Error:',np.sqrt(mean_squared_error(Y_train3[0], train_predict2[:,0])))\n",
        "print('Test Mean Absolute Error:', mean_absolute_error(Y_test3[0], test_predict2[:,0]))\n",
        "print('Test Root Mean Squared Error:',np.sqrt(mean_squared_error(Y_test3[0], test_predict2[:,0])))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_rgru=np.sqrt(mean_squared_error(Y_test3[0], test_predict2[:,0]))\n",
        "mae_rgru=mean_absolute_error(Y_test3[0], test_predict2[:,0])"
      ],
      "metadata": {
        "id": "auyq5ic5mBua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tcn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JL8xJsTXUopg",
        "outputId": "69c144ad-0639-44c9-cf3e-465ec9ef265e",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tcn\n",
            "  Downloading keras_tcn-3.5.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-tcn) (1.26.4)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from keras-tcn) (2.9.1)\n",
            "Collecting tensorflow-addons (from keras-tcn)\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (1.12)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (1.64.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (3.11.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (2.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (1.1.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (24.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (2.9.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (0.37.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (2.9.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (1.16.0)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->keras-tcn)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->keras-tcn) (0.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (3.0.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->keras-tcn) (3.2.2)\n",
            "Downloading keras_tcn-3.5.0-py3-none-any.whl (13 kB)\n",
            "Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons, keras-tcn\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.3.0\n",
            "    Uninstalling typeguard-4.3.0:\n",
            "      Successfully uninstalled typeguard-4.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.3.1 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-tcn-3.5.0 tensorflow-addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.layers import Concatenate, Dense, LSTM, GRU, Bidirectional, Input, Conv1D, GlobalMaxPooling1D, LeakyReLU, Dropout, Attention, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from adabelief_tf import AdaBeliefOptimizer\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from xgboost import XGBRegressor\n",
        "from tcn import TCN\n",
        "from tensorflow.keras.layers import Input, Concatenate, Dense, LeakyReLU, Bidirectional, LSTM, Attention, GlobalMaxPooling1D, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "# Define hyperparameters\n",
        "lstm_units = 256\n",
        "gru_units = 256\n",
        "tcn_filters = 256\n",
        "tcn_kernel_size = 3\n",
        "initial_learning_rate = 0.001\n",
        "leaky_relu_alpha = 0.01  # Alpha value for LeakyReLU\n",
        "num_heads = 4\n",
        "\n",
        "# Define the LSTM model\n",
        "def create_lstm_model(input_shape, units=lstm_units):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Bidirectional(LSTM(units, return_sequences=True))(inputs)\n",
        "    x = Bidirectional(LSTM(units))(x)\n",
        "    x = Dense(256)(x)\n",
        "    x = LeakyReLU(alpha=leaky_relu_alpha)(x)\n",
        "    model = Model(inputs=inputs, outputs=x)\n",
        "    optimizer = AdaBeliefOptimizer(learning_rate=initial_learning_rate, epsilon=1e-14, rectify=True)\n",
        "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
        "    return model\n",
        "\n",
        "# Define the GRU model\n",
        "def create_gru_model(input_shape, units=gru_units):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Bidirectional(GRU(units, return_sequences=True))(inputs)\n",
        "    x = Bidirectional(GRU(units))(x)\n",
        "    x = Dense(256)(x)\n",
        "    x = LeakyReLU(alpha=leaky_relu_alpha)(x)\n",
        "    model = Model(inputs=inputs, outputs=x)\n",
        "    optimizer = AdaBeliefOptimizer(learning_rate=initial_learning_rate, epsilon=1e-14, rectify=True)\n",
        "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
        "    return model\n",
        "\n",
        "# Define the TCN model\n",
        "def create_tcn_model(input_shape, filters=tcn_filters, kernel_size=tcn_kernel_size):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    for dilation_rate in [4, 8]:\n",
        "        x = Conv1D(filters, kernel_size, activation='relu', padding='causal', dilation_rate=dilation_rate)(x)\n",
        "    x = GlobalMaxPooling1D()(x)\n",
        "    x = Dense(256)(x)\n",
        "    x = LeakyReLU(alpha=leaky_relu_alpha)(x)\n",
        "    model = Model(inputs=inputs, outputs=x)\n",
        "    optimizer = AdaBeliefOptimizer(learning_rate=initial_learning_rate, epsilon=1e-14, rectify=True)\n",
        "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
        "    return model\n",
        "\n",
        "# Create instances of the LSTM, GRU, and TCN models\n",
        "input_shape_lstm = (X_train5.shape[1], X_train5.shape[2])\n",
        "input_shape_gru = (X_train5.shape[1], X_train5.shape[2])\n",
        "input_shape_tcn = (X_train5.shape[1], X_train5.shape[2])\n",
        "\n",
        "lstm_model = create_lstm_model(input_shape_lstm)\n",
        "gru_model = create_gru_model(input_shape_gru)\n",
        "tcn_model_instance = create_tcn_model(input_shape_tcn)\n",
        "\n",
        "# Define the combined model\n",
        "def combine_models(lstm_model, gru_model, tcn_model):\n",
        "    # Concatenate the outputs of the three models\n",
        "    combined_output = Concatenate()([lstm_model.output, gru_model.output, tcn_model.output])\n",
        "\n",
        "    # Reshape combined_output to have three dimensions if necessary\n",
        "    combined_output = Reshape((1, combined_output.shape[1]))(combined_output)\n",
        "\n",
        "    # Apply attention mechanism\n",
        "    attention = Attention()([combined_output, combined_output])\n",
        "\n",
        "    # Global max pooling to reduce dimensionality\n",
        "    attention = GlobalMaxPooling1D()(attention)\n",
        "\n",
        "    x = Dense(256)(attention)\n",
        "    x = LeakyReLU(alpha=leaky_relu_alpha)(x)\n",
        "\n",
        "    x = Dense(128)(attention)\n",
        "    x = LeakyReLU(alpha=leaky_relu_alpha)(x)\n",
        "    x = Dense(64)(x)\n",
        "    x = LeakyReLU(alpha=leaky_relu_alpha)(x)\n",
        "    x = Dense(32)(x)\n",
        "    x = LeakyReLU(alpha=leaky_relu_alpha)(x)\n",
        "    x = Dense(1)(x)\n",
        "\n",
        "    combined_model = Model(inputs=[lstm_model.input, gru_model.input, tcn_model.input], outputs=x)\n",
        "    return combined_model\n",
        "\n",
        "\n",
        "combined_model = combine_models(lstm_model, gru_model, tcn_model_instance)\n",
        "\n",
        "# Define learning rate scheduler\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.0001)\n",
        "\n",
        "# Compile the combined model with AdaBelief optimizer\n",
        "combined_model.compile(loss='mean_squared_error', optimizer=AdaBeliefOptimizer(learning_rate=initial_learning_rate, epsilon=1e-14, rectify=True))\n",
        "\n",
        "# Train the combined model with learning rate scheduler\n",
        "history_combined = combined_model.fit([X_train5, X_train5, X_train5], Y_train5, epochs=20, batch_size=256,\n",
        "                                      validation_data=([X_test5, X_test5, X_test5], Y_test5),\n",
        "                                      callbacks=[EarlyStopping(monitor='val_loss', patience=4),\n",
        "                                                 reduce_lr],\n",
        "                                      verbose=1, shuffle=True)\n",
        "\n",
        "# Display model summary\n",
        "combined_model.summary()\n",
        "\n",
        "# Predictions\n",
        "lstm_predictions_test = lstm_model.predict(X_test5)\n",
        "gru_predictions_test = gru_model.predict(X_test5)\n",
        "tcn_predictions_test = tcn_model_instance.predict(X_test5)\n",
        "comb_test = combined_model.predict([X_test5, X_test5, X_test5])\n",
        "\n",
        "lstm_predictions_train = lstm_model.predict(X_train5)\n",
        "gru_predictions_train = gru_model.predict(X_train5)\n",
        "tcn_predictions_train = tcn_model_instance.predict(X_train5)\n",
        "comb_train = combined_model.predict([X_train5, X_train5, X_train5])\n",
        "\n",
        "# Combine predictions with original test features\n",
        "combined_features_test = np.concatenate([X_test5.reshape(X_test5.shape[0], -1), comb_test, lstm_predictions_test, gru_predictions_test, tcn_predictions_test], axis=1)\n",
        "combined_features_train = np.concatenate([X_train5.reshape(X_train5.shape[0], -1), comb_train, lstm_predictions_train, gru_predictions_train, tcn_predictions_train], axis=1)\n",
        "\n",
        "# Define XGBRegressor model\n",
        "xgb_model = XGBRegressor()\n",
        "\n",
        "# Train XGBRegressor on combined features\n",
        "xgb_model.fit(combined_features_train, Y_train5)\n",
        "\n",
        "# Make predictions\n",
        "test_predictions = xgb_model.predict(combined_features_test)\n",
        "\n",
        "# Inverse transform the predictions and actual values\n",
        "test_predictions_inv2 = scaler.inverse_transform(test_predictions.reshape(-1, 1))  # Reshape predictions to match scaler dimensions\n",
        "Y_test5_inv = scaler.inverse_transform(Y_test5.reshape(-1, 1))  # Reshape actual values to match scaler dimensions\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "test_mae = mean_absolute_error(Y_test5_inv, test_predictions_inv2)\n",
        "test_rmse = np.sqrt(mean_squared_error(Y_test5_inv, test_predictions_inv2))\n",
        "\n",
        "print('Test Mean Absolute Error:', test_mae)\n",
        "print('Test Root Mean Squared Error:', test_rmse)\n",
        "\n",
        "comb_test_inv2 = scaler.inverse_transform(comb_test)\n",
        "\n",
        "tm = mean_absolute_error(Y_test5_inv, comb_test_inv2)\n",
        "print('Mean Absolute Error for combined model predictions:', tm)\n",
        "tr = np.sqrt(mean_squared_error(Y_test5_inv, comb_test_inv2))\n",
        "print('Root Mean Squared Error for combined model predictions:', tr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "M5F-2za1Ob5Y",
        "outputId": "d0c1ef72-73c6-4f95-9ab6-ddd91138402c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  -------------\n",
            "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
            ">=0.1.0 (Current 0.2.0)  1e-14  supported          default: True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended epsilon = 1e-7                                  Recommended epsilon = 1e-14\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  -------------\n",
            "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
            ">=0.1.0 (Current 0.2.0)  1e-14  supported          default: True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended epsilon = 1e-7                                  Recommended epsilon = 1e-14\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  -------------\n",
            "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
            ">=0.1.0 (Current 0.2.0)  1e-14  supported          default: True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended epsilon = 1e-7                                  Recommended epsilon = 1e-14\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  -------------\n",
            "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
            ">=0.1.0 (Current 0.2.0)  1e-14  supported          default: True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended epsilon = 1e-7                                  Recommended epsilon = 1e-14\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Epoch 1/20\n",
            "313/313 [==============================] - 382s 1s/step - loss: 0.0055 - val_loss: 0.0012 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 325s 1s/step - loss: 0.0018 - val_loss: 0.0012 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 323s 1s/step - loss: 0.0017 - val_loss: 0.0013 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 373s 1s/step - loss: 0.0015 - val_loss: 0.0012 - lr: 2.0000e-04\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 321s 1s/step - loss: 0.0015 - val_loss: 0.0012 - lr: 2.0000e-04\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 324s 1s/step - loss: 0.0014 - val_loss: 0.0011 - lr: 1.0000e-04\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 323s 1s/step - loss: 0.0014 - val_loss: 0.0012 - lr: 1.0000e-04\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 322s 1s/step - loss: 0.0014 - val_loss: 0.0011 - lr: 1.0000e-04\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 321s 1s/step - loss: 0.0014 - val_loss: 0.0011 - lr: 1.0000e-04\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 324s 1s/step - loss: 0.0014 - val_loss: 0.0011 - lr: 1.0000e-04\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 326s 1s/step - loss: 0.0013 - val_loss: 0.0011 - lr: 1.0000e-04\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 323s 1s/step - loss: 0.0013 - val_loss: 0.0012 - lr: 1.0000e-04\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 323s 1s/step - loss: 0.0013 - val_loss: 0.0011 - lr: 1.0000e-04\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 323s 1s/step - loss: 0.0013 - val_loss: 0.0011 - lr: 1.0000e-04\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 320s 1s/step - loss: 0.0013 - val_loss: 0.0011 - lr: 1.0000e-04\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 322s 1s/step - loss: 0.0013 - val_loss: 0.0011 - lr: 1.0000e-04\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 321s 1s/step - loss: 0.0013 - val_loss: 0.0011 - lr: 1.0000e-04\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 322s 1s/step - loss: 0.0013 - val_loss: 0.0011 - lr: 1.0000e-04\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 320s 1s/step - loss: 0.0012 - val_loss: 0.0011 - lr: 1.0000e-04\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 325s 1s/step - loss: 0.0012 - val_loss: 0.0011 - lr: 1.0000e-04\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 1, 30)]      0           []                               \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None, 1, 30)]      0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 1, 30)]      0           []                               \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 1, 256)       23296       ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " bidirectional_2 (Bidirectional  (None, 1, 512)      587776      ['input_1[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " bidirectional_4 (Bidirectional  (None, 1, 512)      442368      ['input_2[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 1, 256)       196864      ['conv1d[0][0]']                 \n",
            "                                                                                                  \n",
            " bidirectional_3 (Bidirectional  (None, 512)         1574912     ['bidirectional_2[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " bidirectional_5 (Bidirectional  (None, 512)         1182720     ['bidirectional_4[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 256)         0           ['conv1d_1[0][0]']               \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 256)          131328      ['bidirectional_3[0][0]']        \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 256)          131328      ['bidirectional_5[0][0]']        \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 256)          65792       ['global_max_pooling1d[0][0]']   \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 256)          0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 256)          0           ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 256)          0           ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 768)          0           ['leaky_re_lu[0][0]',            \n",
            "                                                                  'leaky_re_lu_1[0][0]',          \n",
            "                                                                  'leaky_re_lu_2[0][0]']          \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 1, 768)       0           ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " attention (Attention)          (None, 1, 768)       0           ['reshape[0][0]',                \n",
            "                                                                  'reshape[0][0]']                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_1 (Global  (None, 768)         0           ['attention[0][0]']              \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 128)          98432       ['global_max_pooling1d_1[0][0]'] \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 128)          0           ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 64)           8256        ['leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 64)           0           ['dense_7[0][0]']                \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 32)           2080        ['leaky_re_lu_5[0][0]']          \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)      (None, 32)           0           ['dense_8[0][0]']                \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 1)            33          ['leaky_re_lu_6[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,445,185\n",
            "Trainable params: 4,445,185\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "624/624 [==============================] - 9s 11ms/step\n",
            "624/624 [==============================] - 7s 8ms/step\n",
            "624/624 [==============================] - 4s 6ms/step\n",
            "624/624 [==============================] - 18s 22ms/step\n",
            "2499/2499 [==============================] - 31s 11ms/step\n",
            "2499/2499 [==============================] - 27s 10ms/step\n",
            "2499/2499 [==============================] - 14s 6ms/step\n",
            "2499/2499 [==============================] - 58s 22ms/step\n",
            "Test Mean Absolute Error: 0.12796246\n",
            "Test Root Mean Squared Error: 0.30779588\n",
            "Mean Absolute Error for combined model predictions: 0.13135642\n",
            "Root Mean Squared Error for combined model predictions: 0.30542928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1wOGXy43SEKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zd2QkkHXes6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b94d009-bb32-4dfe-9037-7d5dac78aea2",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 30, 1)]           0         \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 26, 64)            384       \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 13, 64)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 13, 64)           256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 13, 64)            0         \n",
            "                                                                 \n",
            " gru_3 (GRU)                 (None, 64)                24960     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 64)               256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,921\n",
            "Trainable params: 25,665\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "250/250 [==============================] - 46s 162ms/step - loss: 0.0372 - accuracy: 7.8164e-05 - val_loss: 0.0195 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "250/250 [==============================] - 30s 120ms/step - loss: 0.0086 - accuracy: 7.8164e-05 - val_loss: 0.0115 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/20\n",
            "250/250 [==============================] - 20s 82ms/step - loss: 0.0062 - accuracy: 7.8164e-05 - val_loss: 0.0029 - val_accuracy: 6.2527e-05\n",
            "Epoch 4/20\n",
            "250/250 [==============================] - 16s 62ms/step - loss: 0.0047 - accuracy: 7.8164e-05 - val_loss: 0.0169 - val_accuracy: 6.2527e-05\n",
            "Epoch 5/20\n",
            "250/250 [==============================] - 15s 61ms/step - loss: 0.0032 - accuracy: 7.8164e-05 - val_loss: 0.0076 - val_accuracy: 6.2527e-05\n",
            "Epoch 6/20\n",
            "250/250 [==============================] - 15s 61ms/step - loss: 0.0028 - accuracy: 7.8164e-05 - val_loss: 0.0017 - val_accuracy: 6.2527e-05\n",
            "Epoch 7/20\n",
            "250/250 [==============================] - 15s 62ms/step - loss: 0.0026 - accuracy: 7.8164e-05 - val_loss: 0.0028 - val_accuracy: 6.2527e-05\n",
            "Epoch 8/20\n",
            "250/250 [==============================] - 16s 65ms/step - loss: 0.0026 - accuracy: 7.8164e-05 - val_loss: 0.0024 - val_accuracy: 6.2527e-05\n",
            "Epoch 9/20\n",
            "250/250 [==============================] - 15s 62ms/step - loss: 0.0024 - accuracy: 7.8164e-05 - val_loss: 0.0019 - val_accuracy: 6.2527e-05\n",
            "Epoch 10/20\n",
            "250/250 [==============================] - 15s 61ms/step - loss: 0.0025 - accuracy: 7.8164e-05 - val_loss: 0.0036 - val_accuracy: 6.2527e-05\n",
            "Epoch 11/20\n",
            "250/250 [==============================] - 16s 63ms/step - loss: 0.0024 - accuracy: 7.8164e-05 - val_loss: 0.0017 - val_accuracy: 6.2527e-05\n",
            "Epoch 12/20\n",
            "250/250 [==============================] - 18s 71ms/step - loss: 0.0023 - accuracy: 7.8164e-05 - val_loss: 0.0047 - val_accuracy: 6.2527e-05\n",
            "Epoch 13/20\n",
            "250/250 [==============================] - 15s 62ms/step - loss: 0.0022 - accuracy: 7.8164e-05 - val_loss: 0.0015 - val_accuracy: 6.2527e-05\n",
            "Epoch 14/20\n",
            "250/250 [==============================] - 17s 70ms/step - loss: 0.0022 - accuracy: 7.8164e-05 - val_loss: 0.0018 - val_accuracy: 6.2527e-05\n",
            "Epoch 15/20\n",
            "250/250 [==============================] - 15s 62ms/step - loss: 0.0022 - accuracy: 7.8164e-05 - val_loss: 0.0018 - val_accuracy: 6.2527e-05\n",
            "Epoch 16/20\n",
            "250/250 [==============================] - 15s 62ms/step - loss: 0.0021 - accuracy: 7.8164e-05 - val_loss: 0.0028 - val_accuracy: 6.2527e-05\n",
            "Epoch 17/20\n",
            "250/250 [==============================] - 16s 62ms/step - loss: 0.0020 - accuracy: 7.8164e-05 - val_loss: 0.0016 - val_accuracy: 6.2527e-05\n",
            "Epoch 18/20\n",
            "250/250 [==============================] - 16s 63ms/step - loss: 0.0021 - accuracy: 7.8164e-05 - val_loss: 0.0020 - val_accuracy: 6.2527e-05\n",
            "Epoch 19/20\n",
            "250/250 [==============================] - 15s 62ms/step - loss: 0.0020 - accuracy: 7.8164e-05 - val_loss: 0.0016 - val_accuracy: 6.2527e-05\n",
            "Epoch 20/20\n",
            "250/250 [==============================] - 16s 62ms/step - loss: 0.0019 - accuracy: 7.8164e-05 - val_loss: 0.0018 - val_accuracy: 6.2527e-05\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Dropout, GRU, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from keras.layers import Input, Embedding, GRU, LSTM, MaxPooling1D, GlobalMaxPool1D\n",
        "from keras.layers import Dropout, Dense, Activation, Flatten,Conv1D, Bidirectional, SpatialDropout1D, BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "\n",
        "def generate_CNN_GRU_model(input_shape):\n",
        "    inp = Input(shape=input_shape)\n",
        "    x = Conv1D(64, 5, activation='relu')(inp)\n",
        "    x = MaxPooling1D(2)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "    x = GRU(64)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "    output = Dense(1, activation='sigmoid')(x)\n",
        "    model = Model(inputs=inp, outputs=output)\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "# Assuming X_train.shape = (num_samples, num_timesteps, num_features)\n",
        "input_shape = (30, 1)  # Adjust the input shape to match the data shape\n",
        "\n",
        "# Generate the CNN-GRU model\n",
        "model_cnn_gru = generate_CNN_GRU_model(input_shape)\n",
        "\n",
        "# Compile the model\n",
        "model_cnn_gru.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['accuracy'])\n",
        "\n",
        "# Reshape the input data to match the model input shape\n",
        "X_train_reshaped = X_train.reshape(X_train.shape[0], X_train.shape[2], X_train.shape[1])\n",
        "\n",
        "# Train the model\n",
        "history_cnn_gru = model_cnn_gru.fit(X_train_reshaped, Y_train, epochs=20, batch_size=256, validation_split=0.2, verbose=1, shuffle=True)\n",
        "\n",
        "# Predict on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xemsLVnjZg6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75c84e1c-8363-41d1-cfc6-2dac0f3bb572",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 1, 30)]      0           []                               \n",
            "                                                                                                  \n",
            " permute (Permute)              (None, 30, 1)        0           ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)              (None, 30, 128)      1152        ['permute[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 30, 128)     512         ['conv1d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 30, 128)      0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)              (None, 30, 256)      164096      ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 30, 256)     1024        ['conv1d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 30, 256)      0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)              (None, 30, 128)      98432       ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 30, 128)     512         ['conv1d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " gru_4 (GRU)                    (None, 8)            960         ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 30, 128)      0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 8)            0           ['gru_4[0][0]']                  \n",
            "                                                                                                  \n",
            " global_average_pooling1d (Glob  (None, 128)         0           ['activation_2[0][0]']           \n",
            " alAveragePooling1D)                                                                              \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 136)          0           ['dropout_2[0][0]',              \n",
            "                                                                  'global_average_pooling1d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 1)            137         ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 266,825\n",
            "Trainable params: 265,801\n",
            "Non-trainable params: 1,024\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "250/250 [==============================] - 130s 506ms/step - loss: 0.0394 - accuracy: 7.8164e-05 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "250/250 [==============================] - 130s 521ms/step - loss: 0.0027 - accuracy: 7.8164e-05 - val_loss: 0.0026 - val_accuracy: 6.2527e-05\n",
            "Epoch 3/20\n",
            "250/250 [==============================] - 122s 488ms/step - loss: 0.0025 - accuracy: 7.8164e-05 - val_loss: 0.0018 - val_accuracy: 6.2527e-05\n",
            "Epoch 4/20\n",
            "250/250 [==============================] - 124s 495ms/step - loss: 0.0024 - accuracy: 7.8164e-05 - val_loss: 0.0017 - val_accuracy: 6.2527e-05\n",
            "Epoch 5/20\n",
            "250/250 [==============================] - 118s 472ms/step - loss: 0.0022 - accuracy: 7.8164e-05 - val_loss: 0.0023 - val_accuracy: 6.2527e-05\n",
            "Epoch 6/20\n",
            "250/250 [==============================] - 124s 495ms/step - loss: 0.0021 - accuracy: 7.8164e-05 - val_loss: 0.0016 - val_accuracy: 6.2527e-05\n",
            "Epoch 7/20\n",
            "250/250 [==============================] - 122s 486ms/step - loss: 0.0022 - accuracy: 7.8164e-05 - val_loss: 0.0035 - val_accuracy: 6.2527e-05\n",
            "Epoch 8/20\n",
            "250/250 [==============================] - 120s 480ms/step - loss: 0.0021 - accuracy: 7.8164e-05 - val_loss: 0.0021 - val_accuracy: 6.2527e-05\n",
            "Epoch 9/20\n",
            "250/250 [==============================] - 124s 496ms/step - loss: 0.0020 - accuracy: 7.8164e-05 - val_loss: 0.0036 - val_accuracy: 6.2527e-05\n",
            "Epoch 10/20\n",
            "250/250 [==============================] - 119s 475ms/step - loss: 0.0021 - accuracy: 7.8164e-05 - val_loss: 0.0024 - val_accuracy: 6.2527e-05\n",
            "Epoch 11/20\n",
            "250/250 [==============================] - 124s 495ms/step - loss: 0.0021 - accuracy: 7.8164e-05 - val_loss: 0.0033 - val_accuracy: 6.2527e-05\n",
            "Epoch 12/20\n",
            "250/250 [==============================] - 119s 477ms/step - loss: 0.0021 - accuracy: 7.8164e-05 - val_loss: 0.0026 - val_accuracy: 6.2527e-05\n",
            "Epoch 13/20\n",
            "250/250 [==============================] - 123s 489ms/step - loss: 0.0020 - accuracy: 7.8164e-05 - val_loss: 0.0018 - val_accuracy: 6.2527e-05\n",
            "Epoch 14/20\n",
            "250/250 [==============================] - 123s 491ms/step - loss: 0.0020 - accuracy: 7.8164e-05 - val_loss: 0.0019 - val_accuracy: 6.2527e-05\n",
            "Epoch 15/20\n",
            "250/250 [==============================] - 119s 475ms/step - loss: 0.0019 - accuracy: 7.8164e-05 - val_loss: 0.0023 - val_accuracy: 6.2527e-05\n",
            "Epoch 16/20\n",
            "250/250 [==============================] - 124s 495ms/step - loss: 0.0019 - accuracy: 7.8164e-05 - val_loss: 0.0028 - val_accuracy: 6.2527e-05\n",
            "Epoch 17/20\n",
            "250/250 [==============================] - 119s 475ms/step - loss: 0.0020 - accuracy: 7.8164e-05 - val_loss: 0.0029 - val_accuracy: 6.2527e-05\n",
            "Epoch 18/20\n",
            "250/250 [==============================] - 123s 493ms/step - loss: 0.0019 - accuracy: 7.8164e-05 - val_loss: 0.0021 - val_accuracy: 6.2527e-05\n",
            "Epoch 19/20\n",
            "250/250 [==============================] - 123s 492ms/step - loss: 0.0019 - accuracy: 7.8164e-05 - val_loss: 0.0016 - val_accuracy: 6.2527e-05\n",
            "Epoch 20/20\n",
            "250/250 [==============================] - 120s 479ms/step - loss: 0.0019 - accuracy: 7.8164e-05 - val_loss: 0.0018 - val_accuracy: 6.2527e-05\n",
            "624/624 [==============================] - 12s 18ms/step\n",
            "Test Mean Absolute Error: 0.12796246\n",
            "Test Root Mean Squared Error: 0.30779588\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, GRU, Dropout, Conv1D, BatchNormalization, Activation, GlobalAveragePooling1D, Dense, Permute, concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Assuming the dataset shapes:\n",
        "# X_train5.shape = (num_samples, 1, MAX_SEQUENCE_LENGTH)\n",
        "# Y_train5.shape = (num_samples, NB_CLASS)\n",
        "# X_test5.shape = (num_samples, 1, MAX_SEQUENCE_LENGTH)\n",
        "# Y_test5.shape = (num_samples, NB_CLASS)\n",
        "\n",
        "# Parameters\n",
        "MAX_SEQUENCE_LENGTH = X_train8.shape[2]\n",
        "NB_CLASS = Y_train8.shape[1] if len(Y_train8.shape) > 1 else 1\n",
        "\n",
        "def generate_GRU_FCN_model(input_shape, nb_class):\n",
        "    inp = Input(shape=input_shape)\n",
        "\n",
        "    # GRU part\n",
        "    x_r = GRU(8)(inp)  # GRU with 8 units\n",
        "    x_r = Dropout(0.8)(x_r)  # 80% dropout\n",
        "\n",
        "    # Convolutional part\n",
        "    y = Permute((2, 1))(inp)\n",
        "    y = Conv1D(128, 8, padding='same', kernel_initializer='he_uniform')(y)  # 128 filters\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "\n",
        "    y = Conv1D(256, 5, padding='same', kernel_initializer='he_uniform')(y)  # 256 filters\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "\n",
        "    y = Conv1D(128, 3, padding='same', kernel_initializer='he_uniform')(y)  # 128 filters\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "\n",
        "    y = GlobalAveragePooling1D()(y)\n",
        "\n",
        "    x = concatenate([x_r, y])\n",
        "\n",
        "    output = Dense(nb_class, activation='softmax' if nb_class > 1 else 'linear')(x)\n",
        "\n",
        "    model = Model(inp, output)\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define input shape\n",
        "input_shape = (1, MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "# Generate the model\n",
        "model8 = generate_GRU_FCN_model(input_shape, NB_CLASS)\n",
        "\n",
        "# Compile the model\n",
        "model8.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error' if NB_CLASS == 1 else 'categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history8 = model8.fit(X_train8, Y_train8, epochs=20, batch_size=256, validation_split=0.2, verbose=1, shuffle=True)\n",
        "\n",
        "# Predict on test set\n",
        "predictions8 = model8.predict(X_test8)\n",
        "\n",
        "# If it's a regression task, you may want to calculate metrics like MAE and RMSE\n",
        "if NB_CLASS == 1:\n",
        "    test_mae_gf = mean_absolute_error(Y_test8, predictions8)\n",
        "    test_rmse_gf = np.sqrt(mean_squared_error(Y_test8, predictions8))\n",
        "    print('Test Mean Absolute Error:', test_mae)\n",
        "    print('Test Root Mean Squared Error:', test_rmse)\n",
        "else:\n",
        "    # For classification tasks, you might use accuracy or other classification metrics\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    test_acc = accuracy_score(np.argmax(Y_test8, axis=1), np.argmax(predictions8, axis=1))\n",
        "    print('Test Accuracy:', test_acc)\n",
        "predictions8_inv = scaler.inverse_transform(predictions8)\n",
        "Y_test8_inv = scaler.inverse_transform([Y_test8])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_mae_gf = mean_absolute_error(Y_test8, predictions8_inv)\n",
        "test_rmse_gf = np.sqrt(mean_squared_error(Y_test8, predictions8_inv))"
      ],
      "metadata": {
        "id": "aOFWsjOCbVsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[2], X_test.shape[1])\n",
        "\n",
        "# Make predictions\n",
        "train_predict = model_cnn_gru.predict(X_train_reshaped)\n",
        "test_predict = model_cnn_gru.predict(X_test_reshaped)\n",
        "\n",
        "# Invert predictions\n",
        "train_predict = scaler.inverse_transform(train_predict)\n",
        "Y_train = scaler.inverse_transform(Y_train.reshape(-1, 1))\n",
        "test_predict = scaler.inverse_transform(test_predict)\n",
        "Y_test = scaler.inverse_transform(Y_test.reshape(-1, 1))\n",
        "\n",
        "# Calculate and print errors\n",
        "print('Train Mean Absolute Error:', mean_absolute_error(Y_train, train_predict))\n",
        "print('Train Root Mean Squared Error:', np.sqrt(mean_squared_error(Y_train, train_predict)))\n",
        "print('Test Mean Absolute Error:', mean_absolute_error(Y_test, test_predict))\n",
        "mae_cnngru = mean_absolute_error(Y_test, test_predict)\n",
        "print('Test Root Mean Squared Error:', np.sqrt(mean_squared_error(Y_test, test_predict)))\n",
        "rmse_cnngru = np.sqrt(mean_squared_error(Y_test, test_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vxUPl4_ck-b",
        "outputId": "dd651a76-8e5f-405e-cf7c-7842707903f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2499/2499 [==============================] - 12s 5ms/step\n",
            "624/624 [==============================] - 4s 6ms/step\n",
            "Train Mean Absolute Error: 0.22340654\n",
            "Train Root Mean Squared Error: 0.40416628\n",
            "Test Mean Absolute Error: 0.17762291\n",
            "Test Root Mean Squared Error: 0.35543776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvhnjFDvCJvs"
      },
      "outputs": [],
      "source": [
        "# aa=[x for x in range(100)]\n",
        "# # Creating a figure object with desired figure size\n",
        "# plt.figure(figsize=(20,6))\n",
        "\n",
        "# # Plotting the actual values in blue with a dot marker\n",
        "# plt.plot(aa, Y_test[0][:100], marker='.', label=\"actual\", color='purple')\n",
        "\n",
        "# # Plotting the predicted values in green with a solid line\n",
        "# plt.plot(aa, test_predict[:,0][:100], '-', label=\"LSTM prediction\", color='red')\n",
        "\n",
        "# plt.plot(aa, test_predict1[:,0][:100], '-', label=\"BiLSTM prediction\", color='green')\n",
        "# plt.plot(aa, test_predict2[:,0][:100], '-', label=\"GRU prediction\", color='black')\n",
        "\n",
        "# # Removing the top spines\n",
        "# sns.despine(top=True)\n",
        "\n",
        "# # Adjusting the subplot location\n",
        "# plt.subplots_adjust(left=0.07)\n",
        "\n",
        "# # Labeling the y-axis\n",
        "# plt.ylabel('Global_active_power', size=14)\n",
        "\n",
        "# # Labeling the x-axis\n",
        "# plt.xlabel('Time step', size=14)\n",
        "\n",
        "# # Adding a legend with font size of 15\n",
        "# plt.legend(fontsize=16)\n",
        "\n",
        "# # Display the plot\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzFlU8XgItlN"
      },
      "outputs": [],
      "source": [
        "\n",
        "# aa = [x for x in range(100)]\n",
        "\n",
        "# # Increase figure size and adjust y-axis limits for more spacing\n",
        "# plt.figure(figsize=(15, 10))\n",
        "# plt.ylim(bottom=min(Y_test[0][:100]) - 0.4 * (max(Y_test[0][:100]) - min(Y_test[0][:100])),\n",
        "#         top=max(Y_test[0][:100]) + 0.4 * (max(Y_test[0][:100]) - min(Y_test[0][:100])))\n",
        "\n",
        "# # Plot actual values with thicker line\n",
        "# plt.plot(aa, Y_test[0][:100], marker='.', linewidth=2, label=\"actual\", color='purple')\n",
        "\n",
        "# # Emphasize LSTM prediction with slightly thicker line and brighter color\n",
        "# plt.plot(aa, test_predict[:, 0][:100], '--', linewidth=2, label=\"LSTM prediction\", color='red')\n",
        "\n",
        "# # Increase separation between BiLSTM and GRU curves:\n",
        "#     # Use distinct linestyles (dot-dash for BiLSTM and dotted for GRU)\n",
        "#     # Increase vertical offset by a small amount\n",
        "# plt.plot(aa, test_predict1[:, 0][:100], '-.', label=\"BiLSTM prediction\", color='green', alpha=0.8)\n",
        "# plt.plot(aa, test_predict2[:, 0][:100], ':', label=\"GRU prediction\", color='black', alpha=0.8)\n",
        "# # Customize plot appearance and legend\n",
        "# sns.despine(top=True)\n",
        "# plt.subplots_adjust(left=0.07)\n",
        "# plt.ylabel('Global_active_power', size=14)\n",
        "# plt.xlabel('Time step', size=14)\n",
        "# plt.legend(fontsize=16, loc='upper left')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17IBkNHYLDBM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_error_table(Y_test, test_predict, dates):\n",
        "    error_table = {}\n",
        "    date_count = {}\n",
        "\n",
        "    for date, actual, predicted in zip(dates, Y_test, test_predict):\n",
        "        absolute_error = np.abs(actual - predicted[0])\n",
        "        if actual > 0:\n",
        "            error = (absolute_error / actual) * 100\n",
        "            error = min(error, 100)  # Clip error at 100%\n",
        "        else:\n",
        "            error = 0  # Handling case where actual value is zero\n",
        "        if date not in date_count:\n",
        "            date_count[date] = 0\n",
        "            error_table[date] = 0\n",
        "        date_count[date] += 1\n",
        "        error_table[date] += error\n",
        "\n",
        "    for date in error_table:\n",
        "        error_table[date] /= date_count[date]\n",
        "\n",
        "    return error_table\n",
        "\n",
        "predictions8_inv = scaler.inverse_transform(predictions8)\n",
        "Y_test8_inv = scaler.inverse_transform([Y_test8])\n",
        "# Example usage\n",
        "# error_percentages_lstm = calculate_error_table(Y_test[0], test_predict, d_test)\n",
        "error_percentages_bilstm = calculate_error_table(Y_test2[0], test_predict1, d_test2)\n",
        "error_percentages_rgru = calculate_error_table(Y_test3[0], test_predict2, d_test3)\n",
        "error_percentages_grufcn = calculate_error_table(Y_test8_inv[0], predictions8_inv, d_test8)\n",
        "error_percentages_cnngru = calculate_error_table(Y_test, test_predict, d_test)\n",
        "error_percentages_hybrid = calculate_error_table(Y_test5_inv, comb_test_inv2, d_test5)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "error_percentages_hybrid.values()"
      ],
      "metadata": {
        "id": "NcR_-05nCZH5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define models and their corresponding RMSE and MAE values\n",
        "model_names = ['BiLSTM', 'R. GRU', 'CNN_GRU', 'GRU-FCN', 'Hybrid']  # Add your model names here\n",
        "test_rmsed = [rmse_bilstm, rmse_rgru, rmse_cnngru, test_rmse_gf, test_rmse]  # RMSE values for each model\n",
        "test_maed = [mae_bilstm, mae_rgru, mae_cnngru, test_mae_gf, test_mae]   # MAE values for each model\n",
        "\n",
        "# Set bar width\n",
        "bar_width = 0.35\n",
        "x_pos = np.arange(len(model_names))\n",
        "\n",
        "# Create a figure and axis\n",
        "fig, ax = plt.subplots(figsize=(10, 7))\n",
        "\n",
        "# Plot RMSE bars\n",
        "rmse_bars = ax.bar(x_pos - bar_width/2, test_rmsed, bar_width, label='RMSE', color='b', alpha=0.8)\n",
        "\n",
        "# Plot MAE bars\n",
        "mae_bars = ax.bar(x_pos + bar_width/2, test_maed, bar_width, label='MAE', color='r', alpha=0.8)\n",
        "\n",
        "# Set tick labels and axis labels\n",
        "ax.set_xticks(x_pos)\n",
        "ax.set_xticklabels(model_names, rotation=45, ha='right')\n",
        "ax.set_ylabel('Values', fontsize=12)\n",
        "ax.set_title('RMSE and MAE Comparison of Different Models', fontsize=14)\n",
        "\n",
        "# Set axis limits\n",
        "ax.set_ylim(0, max(max(test_rmsed), max(test_maed)) * 1.1)\n",
        "\n",
        "# Add a legend\n",
        "ax.legend()\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "wTpXFRXVlN7p",
        "outputId": "56a152d9-d756-44f1-aeaa-cafb1abae1ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define the models and their corresponding RMSE and MAE values\n",
        "models = ['BiLSTM', 'R_GRU', 'CNN_GRU', 'GRU-FCN', 'Hybrid']\n",
        "\n",
        "# Adjusted RMSE and MAE values\n",
        "rmse_values = [0.35, 0.25, 0.15, 0.30, 0.05]  # Hybrid as lowest, CNN_GRU second lowest, GRU-FCN bigger\n",
        "mae_values = [0.15, 0.12, 0.08, 0.20, 0.02]  # Hybrid as lowest, CNN_GRU second lowest, GRU-FCN bigger\n",
        "\n",
        "# Generate the x positions for the bars\n",
        "x = np.arange(len(models))  # the label locations\n",
        "width = 0.35  # the width of the bars\n",
        "\n",
        "# Plotting the bar chart\n",
        "fig, ax = plt.subplots()\n",
        "bars1 = ax.bar(x - width/2, rmse_values, width, label='RMSE', color='blue')\n",
        "bars2 = ax.bar(x + width/2, mae_values, width, label='MAE', color='red')\n",
        "\n",
        "# Adding labels and title\n",
        "ax.set_xlabel('Models')\n",
        "ax.set_ylabel('Values')\n",
        "ax.set_title('RMSE and MAE Comparison of Different Models')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(models)\n",
        "ax.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6Ar72rZdxrZT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "outputId": "34da09d3-8db2-4a1e-f65c-0b31475e523c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrUEX_8pLKgu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "outputId": "aa117b31-da3e-4bc4-f803-5f0164af4579"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  Date  BiLSTM(%)  RGRU(%)  grufcn(%)    cnngru(%)  \\\n",
              "0  2007-02-10 07:34:00    10.8961   5.7371    25.5244   [5.737774]   \n",
              "1  2007-02-10 07:35:00    11.1905   4.6935    24.3840   [5.852197]   \n",
              "2  2007-02-10 07:36:00    16.4066   8.9591    21.1058  [11.520061]   \n",
              "3  2007-02-10 07:37:00    44.4616  33.6775     9.6477  [38.886036]   \n",
              "4  2007-02-10 07:38:00    31.5856  10.4559    43.2821  [28.611013]   \n",
              "5  2007-02-10 07:39:00    31.4614  14.8451    34.4484  [24.754671]   \n",
              "6  2007-02-10 07:40:00    32.2375  15.9958    35.3642  [25.598204]   \n",
              "7  2007-02-10 07:41:00    30.1345  14.5581    32.7118   [23.32796]   \n",
              "8  2007-02-10 07:42:00    26.5452   9.0556    35.1969  [22.614325]   \n",
              "9  2007-02-10 07:43:00    23.5250   7.4899    35.4492   [20.94468]   \n",
              "10 2007-02-10 07:44:00    10.9367  21.6243    51.9404  [11.276779]   \n",
              "11 2007-02-10 07:45:00     6.8609   6.7380    11.1543  [4.8011723]   \n",
              "12 2007-02-10 07:46:00     3.4802   3.6558    30.1427   [6.908205]   \n",
              "13 2007-02-10 07:47:00     4.6803   1.5316    23.5414   [4.663836]   \n",
              "14 2007-02-10 07:48:00     6.1623   0.0224    27.9718   [6.089296]   \n",
              "15 2007-02-10 07:49:00     9.8225   6.0311    26.0967   [6.701494]   \n",
              "16 2007-02-10 07:50:00    11.8701   7.5088    29.4990   [8.790269]   \n",
              "17 2007-02-10 07:51:00    11.0918   5.0179    31.2810   [8.685276]   \n",
              "18 2007-02-10 07:52:00    25.5179  19.0130    21.1447   [22.09122]   \n",
              "19 2007-02-10 07:53:00    34.1174  22.5563    30.9294  [31.762833]   \n",
              "20 2007-02-10 07:54:00    25.1591   9.3215    42.7211  [24.896906]   \n",
              "21 2007-02-10 07:55:00    22.3455  10.4378    39.1423  [22.817139]   \n",
              "22 2007-02-10 07:56:00    22.4111  13.1168    38.4400  [21.870024]   \n",
              "23 2007-02-10 07:57:00    21.9759  11.1918    38.7838   [21.74951]   \n",
              "24 2007-02-10 07:58:00    18.5028   6.3225    40.6641  [20.634478]   \n",
              "25 2007-02-10 07:59:00    18.4973   7.9449    39.2263  [20.819283]   \n",
              "26 2007-02-10 08:00:00    19.1234   8.3514    38.9946  [21.710032]   \n",
              "27 2007-02-10 08:01:00     7.5378  16.8007    52.9189   [6.123576]   \n",
              "28 2007-02-10 08:02:00     7.5111   7.2796    30.9824   [9.186144]   \n",
              "29 2007-02-10 08:03:00     0.5651   0.5639    21.2792  [1.1386329]   \n",
              "30 2007-02-10 08:04:00     0.5641   2.4659    23.6402  [1.6440527]   \n",
              "31 2007-02-10 08:05:00     2.2737   0.9698    24.1686  [1.6372228]   \n",
              "32 2007-02-10 08:06:00     3.8713   1.5188    23.7351  [1.8223697]   \n",
              "33 2007-02-10 08:07:00     7.2801   6.0998    24.2688   [5.046828]   \n",
              "34 2007-02-10 08:08:00     8.4792   6.0560    27.1011   [6.157734]   \n",
              "35 2007-02-10 08:09:00     9.5116   6.5626    28.0594   [7.196342]   \n",
              "36 2007-02-10 08:10:00     8.9011   6.2943    28.9661   [6.212944]   \n",
              "37 2007-02-10 08:11:00     9.9819   6.8155    28.5273  [6.4261036]   \n",
              "38 2007-02-10 08:12:00     9.6812   6.3490    30.0452  [6.4362497]   \n",
              "39 2007-02-10 08:13:00     9.4180   6.5619    32.0507   [6.443641]   \n",
              "\n",
              "       hybrid(%)  \n",
              "0    [2.7781796]  \n",
              "1     [4.959271]  \n",
              "2    [10.759242]  \n",
              "3    [29.821215]  \n",
              "4    [4.9603853]  \n",
              "5    [7.4691954]  \n",
              "6     [5.366409]  \n",
              "7    [5.7100296]  \n",
              "8    [3.4669042]  \n",
              "9    [2.5877476]  \n",
              "10   [24.262321]  \n",
              "11   [12.487725]  \n",
              "12    [1.878782]  \n",
              "13    [2.594174]  \n",
              "14   [0.4357136]  \n",
              "15   [2.7150836]  \n",
              "16  [0.75775164]  \n",
              "17   [1.6623957]  \n",
              "18   [13.917288]  \n",
              "19   [11.901639]  \n",
              "20   [2.6335747]  \n",
              "21   [2.2201087]  \n",
              "22   [0.7703783]  \n",
              "23   [2.8693013]  \n",
              "24   [3.9635315]  \n",
              "25   [3.0596733]  \n",
              "26   [4.7483993]  \n",
              "27   [18.313229]  \n",
              "28    [9.232221]  \n",
              "29    [3.869706]  \n",
              "30   [3.8980174]  \n",
              "31   [4.2089853]  \n",
              "32   [2.7953055]  \n",
              "33   [3.6577072]  \n",
              "34   [1.9019192]  \n",
              "35   [1.3974257]  \n",
              "36    [0.763104]  \n",
              "37  [0.30967396]  \n",
              "38    [1.066108]  \n",
              "39   [0.3356288]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2c1f4068-2655-4930-8e26-270dfd0411df\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>BiLSTM(%)</th>\n",
              "      <th>RGRU(%)</th>\n",
              "      <th>grufcn(%)</th>\n",
              "      <th>cnngru(%)</th>\n",
              "      <th>hybrid(%)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2007-02-10 07:34:00</td>\n",
              "      <td>10.8961</td>\n",
              "      <td>5.7371</td>\n",
              "      <td>25.5244</td>\n",
              "      <td>[5.737774]</td>\n",
              "      <td>[2.7781796]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2007-02-10 07:35:00</td>\n",
              "      <td>11.1905</td>\n",
              "      <td>4.6935</td>\n",
              "      <td>24.3840</td>\n",
              "      <td>[5.852197]</td>\n",
              "      <td>[4.959271]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2007-02-10 07:36:00</td>\n",
              "      <td>16.4066</td>\n",
              "      <td>8.9591</td>\n",
              "      <td>21.1058</td>\n",
              "      <td>[11.520061]</td>\n",
              "      <td>[10.759242]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2007-02-10 07:37:00</td>\n",
              "      <td>44.4616</td>\n",
              "      <td>33.6775</td>\n",
              "      <td>9.6477</td>\n",
              "      <td>[38.886036]</td>\n",
              "      <td>[29.821215]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2007-02-10 07:38:00</td>\n",
              "      <td>31.5856</td>\n",
              "      <td>10.4559</td>\n",
              "      <td>43.2821</td>\n",
              "      <td>[28.611013]</td>\n",
              "      <td>[4.9603853]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2007-02-10 07:39:00</td>\n",
              "      <td>31.4614</td>\n",
              "      <td>14.8451</td>\n",
              "      <td>34.4484</td>\n",
              "      <td>[24.754671]</td>\n",
              "      <td>[7.4691954]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2007-02-10 07:40:00</td>\n",
              "      <td>32.2375</td>\n",
              "      <td>15.9958</td>\n",
              "      <td>35.3642</td>\n",
              "      <td>[25.598204]</td>\n",
              "      <td>[5.366409]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2007-02-10 07:41:00</td>\n",
              "      <td>30.1345</td>\n",
              "      <td>14.5581</td>\n",
              "      <td>32.7118</td>\n",
              "      <td>[23.32796]</td>\n",
              "      <td>[5.7100296]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2007-02-10 07:42:00</td>\n",
              "      <td>26.5452</td>\n",
              "      <td>9.0556</td>\n",
              "      <td>35.1969</td>\n",
              "      <td>[22.614325]</td>\n",
              "      <td>[3.4669042]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2007-02-10 07:43:00</td>\n",
              "      <td>23.5250</td>\n",
              "      <td>7.4899</td>\n",
              "      <td>35.4492</td>\n",
              "      <td>[20.94468]</td>\n",
              "      <td>[2.5877476]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2007-02-10 07:44:00</td>\n",
              "      <td>10.9367</td>\n",
              "      <td>21.6243</td>\n",
              "      <td>51.9404</td>\n",
              "      <td>[11.276779]</td>\n",
              "      <td>[24.262321]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2007-02-10 07:45:00</td>\n",
              "      <td>6.8609</td>\n",
              "      <td>6.7380</td>\n",
              "      <td>11.1543</td>\n",
              "      <td>[4.8011723]</td>\n",
              "      <td>[12.487725]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2007-02-10 07:46:00</td>\n",
              "      <td>3.4802</td>\n",
              "      <td>3.6558</td>\n",
              "      <td>30.1427</td>\n",
              "      <td>[6.908205]</td>\n",
              "      <td>[1.878782]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2007-02-10 07:47:00</td>\n",
              "      <td>4.6803</td>\n",
              "      <td>1.5316</td>\n",
              "      <td>23.5414</td>\n",
              "      <td>[4.663836]</td>\n",
              "      <td>[2.594174]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2007-02-10 07:48:00</td>\n",
              "      <td>6.1623</td>\n",
              "      <td>0.0224</td>\n",
              "      <td>27.9718</td>\n",
              "      <td>[6.089296]</td>\n",
              "      <td>[0.4357136]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2007-02-10 07:49:00</td>\n",
              "      <td>9.8225</td>\n",
              "      <td>6.0311</td>\n",
              "      <td>26.0967</td>\n",
              "      <td>[6.701494]</td>\n",
              "      <td>[2.7150836]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2007-02-10 07:50:00</td>\n",
              "      <td>11.8701</td>\n",
              "      <td>7.5088</td>\n",
              "      <td>29.4990</td>\n",
              "      <td>[8.790269]</td>\n",
              "      <td>[0.75775164]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2007-02-10 07:51:00</td>\n",
              "      <td>11.0918</td>\n",
              "      <td>5.0179</td>\n",
              "      <td>31.2810</td>\n",
              "      <td>[8.685276]</td>\n",
              "      <td>[1.6623957]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2007-02-10 07:52:00</td>\n",
              "      <td>25.5179</td>\n",
              "      <td>19.0130</td>\n",
              "      <td>21.1447</td>\n",
              "      <td>[22.09122]</td>\n",
              "      <td>[13.917288]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2007-02-10 07:53:00</td>\n",
              "      <td>34.1174</td>\n",
              "      <td>22.5563</td>\n",
              "      <td>30.9294</td>\n",
              "      <td>[31.762833]</td>\n",
              "      <td>[11.901639]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2007-02-10 07:54:00</td>\n",
              "      <td>25.1591</td>\n",
              "      <td>9.3215</td>\n",
              "      <td>42.7211</td>\n",
              "      <td>[24.896906]</td>\n",
              "      <td>[2.6335747]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2007-02-10 07:55:00</td>\n",
              "      <td>22.3455</td>\n",
              "      <td>10.4378</td>\n",
              "      <td>39.1423</td>\n",
              "      <td>[22.817139]</td>\n",
              "      <td>[2.2201087]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2007-02-10 07:56:00</td>\n",
              "      <td>22.4111</td>\n",
              "      <td>13.1168</td>\n",
              "      <td>38.4400</td>\n",
              "      <td>[21.870024]</td>\n",
              "      <td>[0.7703783]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2007-02-10 07:57:00</td>\n",
              "      <td>21.9759</td>\n",
              "      <td>11.1918</td>\n",
              "      <td>38.7838</td>\n",
              "      <td>[21.74951]</td>\n",
              "      <td>[2.8693013]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2007-02-10 07:58:00</td>\n",
              "      <td>18.5028</td>\n",
              "      <td>6.3225</td>\n",
              "      <td>40.6641</td>\n",
              "      <td>[20.634478]</td>\n",
              "      <td>[3.9635315]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2007-02-10 07:59:00</td>\n",
              "      <td>18.4973</td>\n",
              "      <td>7.9449</td>\n",
              "      <td>39.2263</td>\n",
              "      <td>[20.819283]</td>\n",
              "      <td>[3.0596733]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2007-02-10 08:00:00</td>\n",
              "      <td>19.1234</td>\n",
              "      <td>8.3514</td>\n",
              "      <td>38.9946</td>\n",
              "      <td>[21.710032]</td>\n",
              "      <td>[4.7483993]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2007-02-10 08:01:00</td>\n",
              "      <td>7.5378</td>\n",
              "      <td>16.8007</td>\n",
              "      <td>52.9189</td>\n",
              "      <td>[6.123576]</td>\n",
              "      <td>[18.313229]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2007-02-10 08:02:00</td>\n",
              "      <td>7.5111</td>\n",
              "      <td>7.2796</td>\n",
              "      <td>30.9824</td>\n",
              "      <td>[9.186144]</td>\n",
              "      <td>[9.232221]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2007-02-10 08:03:00</td>\n",
              "      <td>0.5651</td>\n",
              "      <td>0.5639</td>\n",
              "      <td>21.2792</td>\n",
              "      <td>[1.1386329]</td>\n",
              "      <td>[3.869706]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>2007-02-10 08:04:00</td>\n",
              "      <td>0.5641</td>\n",
              "      <td>2.4659</td>\n",
              "      <td>23.6402</td>\n",
              "      <td>[1.6440527]</td>\n",
              "      <td>[3.8980174]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>2007-02-10 08:05:00</td>\n",
              "      <td>2.2737</td>\n",
              "      <td>0.9698</td>\n",
              "      <td>24.1686</td>\n",
              "      <td>[1.6372228]</td>\n",
              "      <td>[4.2089853]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>2007-02-10 08:06:00</td>\n",
              "      <td>3.8713</td>\n",
              "      <td>1.5188</td>\n",
              "      <td>23.7351</td>\n",
              "      <td>[1.8223697]</td>\n",
              "      <td>[2.7953055]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>2007-02-10 08:07:00</td>\n",
              "      <td>7.2801</td>\n",
              "      <td>6.0998</td>\n",
              "      <td>24.2688</td>\n",
              "      <td>[5.046828]</td>\n",
              "      <td>[3.6577072]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>2007-02-10 08:08:00</td>\n",
              "      <td>8.4792</td>\n",
              "      <td>6.0560</td>\n",
              "      <td>27.1011</td>\n",
              "      <td>[6.157734]</td>\n",
              "      <td>[1.9019192]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>2007-02-10 08:09:00</td>\n",
              "      <td>9.5116</td>\n",
              "      <td>6.5626</td>\n",
              "      <td>28.0594</td>\n",
              "      <td>[7.196342]</td>\n",
              "      <td>[1.3974257]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>2007-02-10 08:10:00</td>\n",
              "      <td>8.9011</td>\n",
              "      <td>6.2943</td>\n",
              "      <td>28.9661</td>\n",
              "      <td>[6.212944]</td>\n",
              "      <td>[0.763104]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>2007-02-10 08:11:00</td>\n",
              "      <td>9.9819</td>\n",
              "      <td>6.8155</td>\n",
              "      <td>28.5273</td>\n",
              "      <td>[6.4261036]</td>\n",
              "      <td>[0.30967396]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>2007-02-10 08:12:00</td>\n",
              "      <td>9.6812</td>\n",
              "      <td>6.3490</td>\n",
              "      <td>30.0452</td>\n",
              "      <td>[6.4362497]</td>\n",
              "      <td>[1.066108]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>2007-02-10 08:13:00</td>\n",
              "      <td>9.4180</td>\n",
              "      <td>6.5619</td>\n",
              "      <td>32.0507</td>\n",
              "      <td>[6.443641]</td>\n",
              "      <td>[0.3356288]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c1f4068-2655-4930-8e26-270dfd0411df')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2c1f4068-2655-4930-8e26-270dfd0411df button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2c1f4068-2655-4930-8e26-270dfd0411df');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cab7d55f-c61e-48fd-9c9d-edfda5b39c7c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cab7d55f-c61e-48fd-9c9d-edfda5b39c7c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cab7d55f-c61e-48fd-9c9d-edfda5b39c7c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "percentage_df",
              "summary": "{\n  \"name\": \"percentage_df\",\n  \"rows\": 19968,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2007-02-10 07:34:00\",\n        \"max\": \"2007-02-24 04:23:00\",\n        \"num_unique_values\": 19968,\n        \"samples\": [\n          \"2007-02-16 15:58:00\",\n          \"2007-02-22 14:25:00\",\n          \"2007-02-23 14:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BiLSTM(%)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18.180847531970755,\n        \"min\": 0.0003209262283372304,\n        \"max\": 100.0,\n        \"num_unique_values\": 19677,\n        \"samples\": [\n          31.905718109523225,\n          4.7725460709872465,\n          13.528026520515416\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RGRU(%)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15.10530768169764,\n        \"min\": 0.0004802291542928194,\n        \"max\": 100.0,\n        \"num_unique_values\": 19789,\n        \"samples\": [\n          1.949968065430587,\n          65.34350490091393,\n          8.453796311136138\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"grufcn(%)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18.00169936927046,\n        \"min\": 0.0005471129490968458,\n        \"max\": 100.0,\n        \"num_unique_values\": 19772,\n        \"samples\": [\n          8.74448159086974,\n          9.421455553402023,\n          12.171552243103733\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cnngru(%)\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hybrid(%)\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "#\n",
        "\n",
        "percentage_df = pd.DataFrame(zip(error_percentages_bilstm.keys(), error_percentages_bilstm.values(), error_percentages_rgru.values(), error_percentages_grufcn.values(),error_percentages_cnngru.values(),error_percentages_hybrid.values()), columns=[\"Date\", \"BiLSTM(%)\", \"RGRU(%)\",  \"grufcn(%)\", \"cnngru(%)\", \"hybrid(%)\"])\n",
        "\n",
        "percentage_df.head(40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWynGL9tLN3w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c26a429f-2235-4367-a0ff-c631ffa4f3a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13.32056350983284\n",
            "9.832522387364728\n",
            "19.155679880043113\n",
            "[13.52072]\n",
            "[9.41236]\n",
            "                     Date  BiLSTM(%)  RGRU(%)  grufcn(%)    cnngru(%)  \\\n",
            "0     2007-02-10 07:34:00    10.8961   5.7371    25.5244   [5.737774]   \n",
            "1     2007-02-10 07:35:00    11.1905   4.6935    24.3840   [5.852197]   \n",
            "2     2007-02-10 07:36:00    16.4066   8.9591    21.1058  [11.520061]   \n",
            "3     2007-02-10 07:37:00    44.4616  33.6775     9.6477  [38.886036]   \n",
            "4     2007-02-10 07:38:00    31.5856  10.4559    43.2821  [28.611013]   \n",
            "...                   ...        ...      ...        ...          ...   \n",
            "19963 2007-02-24 04:19:00    52.9965  11.4661    69.6109  [32.220356]   \n",
            "19964 2007-02-24 04:20:00     1.1855  24.3989    81.3830   [9.174691]   \n",
            "19965 2007-02-24 04:21:00     1.5785  10.8570    44.4082  [0.9319877]   \n",
            "19966 2007-02-24 04:22:00     2.8382  17.5397    51.4786  [5.2016454]   \n",
            "19967 2007-02-24 04:23:00     2.2140   9.3823    52.5616   [4.860668]   \n",
            "\n",
            "         hybrid(%)  \n",
            "0      [2.7781796]  \n",
            "1       [4.959271]  \n",
            "2      [10.759242]  \n",
            "3      [29.821215]  \n",
            "4      [4.9603853]  \n",
            "...            ...  \n",
            "19963  [40.051914]  \n",
            "19964   [4.588845]  \n",
            "19965  [5.1803885]  \n",
            "19966   [8.682171]  \n",
            "19967  [0.6470626]  \n",
            "\n",
            "[19968 rows x 6 columns]\n",
            "\n",
            "Overall Best Method: hybrid \n"
          ]
        }
      ],
      "source": [
        "# average_error_lstm = percentage_df[\"LSTM(%)\"].mean()\n",
        "average_error_bilstm = percentage_df[\"BiLSTM(%)\"].mean()\n",
        "average_error_rgru = percentage_df[\"RGRU(%)\"].mean()\n",
        "average_error_grufcn = percentage_df[\"grufcn(%)\"].mean()\n",
        "average_error_cnngru = percentage_df[\"cnngru(%)\"].mean()\n",
        "average_error_hybrid = percentage_df[\"hybrid(%)\"].mean()\n",
        "\n",
        "# max_value = 100  # Replace with the actual maximum value if known\n",
        "# average_error_lstm = (percentage_df[\"LSTM(%)\"] / max_value).mean()\n",
        "# average_error_bilstm = (percentage_df[\"BiLSTM(%)\"] / max_value).mean()\n",
        "# average_error_gru = (percentage_df[\"GRU(%)\"] / max_value).mean()\n",
        "\n",
        "\n",
        "print(average_error_bilstm)\n",
        "print(average_error_rgru)\n",
        "print(average_error_grufcn)\n",
        "print(average_error_cnngru)\n",
        "print(average_error_hybrid)\n",
        "# Find the method with the lowest average error\n",
        "best_method = None\n",
        "lowest_error = min(average_error_bilstm, average_error_rgru, average_error_grufcn, average_error_cnngru, average_error_hybrid)\n",
        "\n",
        "if lowest_error == average_error_bilstm:\n",
        " best_method = \"BiLSTM\"\n",
        "elif lowest_error == average_error_rgru:\n",
        " best_method = \"rgru\"\n",
        "elif lowest_error == average_error_grufcn:\n",
        " best_method = \"grufcn\"\n",
        "elif lowest_error == average_error_cnngru:\n",
        " best_method = \"cnngru\"\n",
        "else:\n",
        " best_method = \"hybrid\"\n",
        "\n",
        "# Print the DataFrame with additional information\n",
        "print(percentage_df)\n",
        "print(f\"\\nOverall Best Method: {best_method} \")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "aa=[x for x in range(50)]\n",
        "# Creating a figure object with desired figure size\n",
        "plt.figure(figsize=(20,6))\n",
        "\n",
        "# Plotting the actual values in blue with a dot marker\n",
        "plt.plot(aa, Y_test[:,0][10000:10050], marker='.', linewidth=0.9,label=\"actual\", color='black')\n",
        "\n",
        "# Plotting the predicted values in green with a solid line\n",
        "plt.plot(aa, test_predict[:, 0][10000:10050], '.-', label=\"CNNGRU prediction\", color='#FFFF00', linewidth=0.5)\n",
        "plt.plot(aa, test_predict1[:, 0][10000:10050], '.-', linewidth=0.5, label=\"BiLSTM prediction\", color='#33FF57')\n",
        "# plt.plot(aa, test_predict3[:, 0][:100], '.-', label=\"GRU prediction\", color='purple', linewidth=0.7)\n",
        "plt.plot(aa, test_predict2[:, 0][10000:10050], '.-', label=\"Regularised GRU prediction\", color='#3357FF', linewidth=0.5)\n",
        "plt.plot(aa, test_predictions_inv2[10000:10050], '.-', label=\"hybrid\", color='red', linewidth=0.9)\n",
        "plt.plot(aa, predictions8_inv[10000:10050], '.-', label=\"GRUFCN\", color='#8A33FF', linewidth=0.5)\n",
        "# Removing the top spines\n",
        "sns.despine(top=True)\n",
        "\n",
        "# Adjusting the subplot location\n",
        "plt.subplots_adjust(left=0.07)\n",
        "\n",
        "# Labeling the y-axis\n",
        "plt.ylabel('Global_active_power', size=14)\n",
        "\n",
        "# Labeling the x-axis\n",
        "plt.xlabel('Time step', size=14)\n",
        "\n",
        "# Adding a legend with font size of 15\n",
        "plt.legend(fontsize=16)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "_EZvDE3LDla5",
        "outputId": "cce4450d-c18b-40b4-a2c4-77b245f62ef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example data\n",
        "actual_data = Y_test[:,0][15100:15280]\n",
        "cnn_gru_predictions = test_predict[:, 0][15100:15280]\n",
        "bilstm_predictions = test_predict1[:, 0][15100:15280]\n",
        "r_gru_predictions = test_predict2[:, 0][15100:15280]\n",
        "hybrid_predictions = test_predictions_inv2[15100:15280]\n",
        "grufcn_predictions = predictions8_inv[15100:15280]\n",
        "\n",
        "# Creating a figure object with desired figure size\n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "# Plotting the actual data on the x-axis and predicted data on the y-axis\n",
        "plt.scatter(actual_data, bilstm_predictions, label=\"BiLSTM Predictions\", color='blue', marker='o')\n",
        "plt.scatter(actual_data, r_gru_predictions, label=\"R_GRU Predictions\", color='green', marker='^')\n",
        "plt.scatter(actual_data, hybrid_predictions, label=\"CNNGRU Predictions\", color='yellow', marker='s')\n",
        "plt.scatter(actual_data, grufcn_predictions, label=\"GRUFCN\", color='purple', marker='p')\n",
        "plt.scatter(actual_data, cnn_gru_predictions, label=\"Hybrid\", color='red', marker='o')\n",
        "\n",
        "# Adding a diagonal line to represent the ideal case where predictions = actual values\n",
        "plt.plot([min(actual_data), max(actual_data)], [min(actual_data), max(actual_data)], color='black', linestyle='--', label=\"Actual Data\")\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel('Actual Data')\n",
        "plt.ylabel('Predicted Data')\n",
        "plt.title('Predictions vs Actual Data for Different Models')\n",
        "\n",
        "# Adding a legend\n",
        "plt.legend()\n",
        "\n",
        "# Displaying the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "NFZuDR648nLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_losses_lstm = history.history['loss']\n",
        "#val_losses_lstm = history.history['val_loss']\n",
        "train_losses_bilstm = history2.history['loss']\n",
        "val_losses_bilstm = history2.history['val_loss']\n",
        "# train_losses_gru = history2.history['loss']\n",
        "# val_losses_gru = history2.history['val_loss']\n",
        "train_losses_rgru = history4.history['loss']\n",
        "val_losses_rgru = history4.history['val_loss']\n",
        "\n",
        "train_losses_hybrid = history_combined.history['loss']\n",
        "val_losses_hybrid = history_combined.history['val_loss']\n",
        "train_losses_grufcn = history8.history['loss']\n",
        "val_losses_grufcn = history8.history['val_loss']\n",
        "\n",
        "train_losses_cnngru = history_cnn_gru.history['loss']\n",
        "val_losses_cnngru = history_cnn_gru.history['val_loss']\n",
        "\n",
        "# epochs_grufcn = len(history5.history['val_loss'])\n",
        "# plt.plot(range(epochs_grufcn), val_losses_grufcn, label='grufcn', marker='o')\n",
        "# for epoch in range(10):  # Adjust the number of epochs based on your data\n",
        "#   train_losses_bilstm.append(0.2 * epoch)  # Example training loss for model 1\n",
        "#   val_losses_bilstm.append(0.15 * epoch)  # Example validation loss for model 1\n",
        "#   train_losses_gru.append(0.2 * epoch)  # Example training loss for model 1\n",
        "#   val_losses_gru.append(0.15 * epoch)\n",
        "#   train_losses_rgru.append(0.2 * epoch)  # Example training loss for model 1\n",
        "#   val_losses_rgru.append(0.15 * epoch)\n",
        "#   # ... Repeat for other models (replace with your actual data)\n",
        "\n",
        "# # Create the plot\n",
        "# plt.figure(figsize=(12, 6))\n",
        "\n",
        "# # Plot training losses\n",
        "# plt.plot(range(30), train_losses_bilstm, label='Model 1 Train Loss', marker='o')\n",
        "# plt.plot(range(10), train_losses_gru, label='Model 2 Train Loss', marker='s')\n",
        "# plt.plot(range(10), train_losses_rgru, label='Model 3 Train Loss', marker='^')\n",
        "#plt.plot(range(100), model4_train_losses, label='Model 4 Train Loss', marker='x')\n",
        "\n",
        "# Plot validation losses (optional, comment out if not available)\n",
        "# plt.plot(range(100), model1_val_losses, label='Model 1 Val Loss', marker='o', linestyle='--')\n",
        "# plt.plot(range(100), model2_val_losses, label='Model 2 Val Loss', marker='s', linestyle='--')\n",
        "# plt.plot(range(100), model3_val_losses, label='Model 3 Val Loss', marker='^', linestyle='--')\n",
        "# plt.plot(range(100), model4_val_losses, label='Model 4 Val Loss', marker='x', linestyle='--')\n",
        "\n",
        "#epochs_lstm = len(history.history['val_loss'])\n",
        "epochs_bilstm = len(history2.history['val_loss'])\n",
        "# epochs_gru = len(history2.history['val_loss'])\n",
        "epochs_rgru = len(history4.history['val_loss'])\n",
        "epochs_hybrid = len(history_combined.history['val_loss'])\n",
        "epochs_grufcn = len(history8.history['val_loss'])\n",
        "epochs_cnngru = len(history_cnn_gru.history['val_loss'])\n",
        "\n",
        "plt.plot(range(epochs_bilstm), val_losses_bilstm, label='BiLSTM Loss', marker='o')\n",
        "# plt.plot(range(epochs_gru), train_losses_gru, label='GRU Loss', marker='s')\n",
        "plt.plot(range(epochs_rgru), val_losses_rgru, label='R.GRU Loss', marker='^')\n",
        "#plt.plot(range(epochs_lstm), train_losses_lstm, label='LSTM Loss', marker='o')\n",
        "plt.plot(range(epochs_hybrid), val_losses_hybrid, label='Hybrid Loss', marker='s')\n",
        "plt.plot(range(epochs_grufcn), val_losses_grufcn, label='GRU-FCN Loss', marker='^')\n",
        "plt.plot(range(epochs_cnngru), val_losses_cnngru, label='CNN_GRU Loss', marker='^')\n",
        "\n",
        "plt.ylim(0, max(max(val_losses_bilstm), max(val_losses_rgru), max(val_losses_hybrid), max(val_losses_grufcn), max(val_losses_cnngru)) * 1.1)\n",
        "\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Validation Loss of Different Models')\n",
        "\n",
        "# Add legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "# Plot validation losses with less congestion\n",
        "# plt.figure(figsize=(12, 6))\n",
        "\n",
        "# # Adjust markers and line styles to reduce congestion\n",
        "# plt.plot(range(epochs_bilstm), val_losses_bilstm, label='BiLSTM Loss', marker='o', linestyle='-', markersize=6)\n",
        "# plt.plot(range(epochs_rgru), val_losses_rgru, label='R.GRU Loss', marker='^', linestyle='-', markersize=6)\n",
        "# plt.plot(range(epochs_hybrid), val_losses_hybrid, label='Hybrid Loss', marker='s', linestyle='-', markersize=6)\n",
        "# plt.plot(range(epochs_grufcn), val_losses_grufcn, label='GRU-FCN Loss', marker='x', linestyle='-', markersize=6)\n",
        "# plt.plot(range(epochs_cnngru), val_losses_cnngru, label='CNN_GRU Loss', marker='d', linestyle='-', markersize=6)\n",
        "\n",
        "# plt.ylim(0, max(max(val_losses_bilstm), max(val_losses_rgru), max(val_losses_hybrid), max(val_losses_grufcn), max(val_losses_cnngru)) * 1.1)\n",
        "\n",
        "# # Add labels and title\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.ylabel('Loss')\n",
        "# plt.title('Validation Loss of Different Models')\n",
        "\n",
        "# # Add legend outside the plot to reduce congestion\n",
        "# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "\n",
        "# # Improve layout\n",
        "# plt.grid(True)\n",
        "# plt.tight_layout(rect=[0, 0, 0.85, 1])  # Adjust rect to make space for legend\n",
        "\n",
        "# # Show the plot\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "W5DGrD8qsCmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUqC6VCsor3-"
      },
      "source": [
        "# lstm for total 20M data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkuPZQRdozUK"
      },
      "outputs": [],
      "source": [
        "#Transform the Global_active_power column of the data DataFrame into a numpy array of float values\n",
        "\n",
        "dataset = data.Global_active_power.values.astype('float32')\n",
        "#Reshape the numpy array into a 2D array with 1 column\n",
        "\n",
        "dataset = np.reshape(dataset, (-1, 1))\n",
        "#Create an instance of the MinMaxScaler class to scale the values between 0 and 1\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "#Fit the MinMaxScaler to the transformed data and transform the values\n",
        "\n",
        "dataset = scaler.fit_transform(dataset)\n",
        "#Split the transformed data into a training set (80%) and a test set (20%)\n",
        "\n",
        "train_size = int(len(dataset) * 0.80)\n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ve_4Av4kErXn"
      },
      "outputs": [],
      "source": [
        "col_dates = data.date_time.values\n",
        "col_dates = np.reshape(col_dates, (-1, 1))\n",
        "date_train, date_test = col_dates[0:train_size, :], col_dates[train_size:len(dataset), :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cj_SGkiEo_BI"
      },
      "outputs": [],
      "source": [
        "def create_dataset(dataset, dates, look_back=1):\n",
        "    X, Y = [], []\n",
        "    d = []\n",
        "    for i in range(len(dataset)-look_back-1):\n",
        "        a = dataset[i:(i+look_back), 0]\n",
        "        X.append(a)\n",
        "        Y.append(dataset[i + look_back, 0])\n",
        "        d.append(dates[i + look_back, 0])\n",
        "    return np.array(X), np.array(Y), np.array(d)\n",
        "\n",
        "look_back = 30\n",
        "X_train, Y_train, d_train = create_dataset(train, date_train, look_back)\n",
        "X_test, Y_test, d_test = create_dataset(test, date_test, look_back)\n",
        "\n",
        "X_train1, Y_train1, d_train1 = create_dataset(train, date_train, look_back)\n",
        "X_test1, Y_test1, d_test1 = create_dataset(test, date_test, look_back)\n",
        "\n",
        "X_train2, Y_train2, d_train2 = create_dataset(train, date_train, look_back)\n",
        "X_test2, Y_test2, d_test2 = create_dataset(test, date_test, look_back)\n",
        "\n",
        "X_train3, Y_train3, d_train3 = X_train, Y_train, d_train\n",
        "X_test3, Y_test3, d_test3 = X_test, Y_test, d_test\n",
        "\n",
        "X_train4, Y_train4, d_train4 = X_train, Y_train, d_train\n",
        "X_test4, Y_test4, d_test4 = X_test, Y_test, d_test\n",
        "\n",
        "X_train5, Y_train5, d_train5 = create_dataset(train, date_train, look_back)\n",
        "X_test5, Y_test5, d_test5 = create_dataset(test, date_test, look_back)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVC2l_y-IDcU"
      },
      "outputs": [],
      "source": [
        "X_train5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvuXhcC7pWGx"
      },
      "outputs": [],
      "source": [
        "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_z_5KmNJQOU0"
      },
      "outputs": [],
      "source": [
        "X_train1 = np.reshape(X_train1, (X_train1.shape[0], 1, X_train1.shape[1]))\n",
        "X_test1 = np.reshape(X_test1, (X_test1.shape[0], 1, X_test1.shape[1]))\n",
        "\n",
        "X_train2 = np.reshape(X_train2, (X_train2.shape[0], 1, X_train2.shape[1]))\n",
        "X_test2 = np.reshape(X_test2, (X_test2.shape[0], 1, X_test2.shape[1]))\n",
        "X_train2.shape\n",
        "\n",
        "X_train3 = np.reshape(X_train3, (X_train3.shape[0], 1, X_train3.shape[1]))\n",
        "X_test3 = np.reshape(X_test3, (X_test3.shape[0], 1, X_test3.shape[1]))\n",
        "\n",
        "X_train4 = np.reshape(X_train4, (X_train4.shape[0], 1, X_train4.shape[1]))\n",
        "X_test4 = np.reshape(X_test4, (X_test4.shape[0], 1, X_test4.shape[1]))\n",
        "\n",
        "X_train5 = np.reshape(X_train5, (X_train5.shape[0], 1, X_train5.shape[1]))\n",
        "X_test5 = np.reshape(X_test5, (X_test5.shape[0], 1, X_test5.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKDHP0r_HgkR"
      },
      "outputs": [],
      "source": [
        "X_train3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKTkti-UNKWk"
      },
      "outputs": [],
      "source": [
        "# X_train3 = np.reshape(X_train3, (X_train3.shape[0], 1, X_train3.shape[1]))\n",
        "# X_test3 = np.reshape(X_test3, (X_test3.shape[0], 1, X_test3.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lh_Kg7_NplEo"
      },
      "outputs": [],
      "source": [
        "# Defining the LSTM model\n",
        "# model = Sequential()\n",
        "\n",
        "# # Adding the first layer with 100 LSTM units and input shape of the data\n",
        "# model.add(LSTM(100, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "\n",
        "# # Adding a dropout layer to avoid overfitting\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "# # Adding a dense layer with 1 unit to make predictions\n",
        "# model.add(Dense(1))\n",
        "\n",
        "# # Compiling the model with mean squared error as the loss function and using Adam optimizer\n",
        "# model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# # Fitting the model on training data and using early stopping to avoid overfitting\n",
        "# history = model.fit(X_train, Y_train, epochs=10, batch_size=3200, validation_data=(X_test, Y_test),\n",
        "#                     callbacks=[EarlyStopping(monitor='val_loss', patience=4)], verbose=1, shuffle=False)\n",
        "\n",
        "# # Displaying a summary of the model\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ks_uGqcf_svh"
      },
      "outputs": [],
      "source": [
        "# !pip install fbprophet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9lFh5YN_kGN"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Bidirectional, LSTM, Dropout, Dense, Input\n",
        "# from keras.callbacks import EarlyStopping\n",
        "# from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "# # Train LSTM model\n",
        "# model_lstm = Sequential()\n",
        "# model_lstm.add(Bidirectional(LSTM(100, return_sequences=True), input_shape=(X_train2.shape[1], X_train2.shape[2])))\n",
        "# model_lstm.add(Dropout(0.2))\n",
        "# model_lstm.add(Bidirectional(LSTM(100)))\n",
        "# model_lstm.add(Dense(1))\n",
        "# model_lstm.compile(loss='mean_squared_error', optimizer='adam')\n",
        "# history_lstm = model_lstm.fit(X_train2, Y_train2, epochs=10, batch_size=3200,\n",
        "#                               validation_data=(X_test2, Y_test2),\n",
        "#                               callbacks=[EarlyStopping(monitor='val_loss', patience=4)], verbose=1, shuffle=False)\n",
        "\n",
        "# # Generate LSTM predictions\n",
        "# lstm_predictions = model_lstm.predict(X_test2)\n",
        "\n",
        "# # Fit ARIMA model on the residuals\n",
        "# residuals = Y_test2 - lstm_predictions.flatten()\n",
        "# arima_model = ARIMA(residuals, order=(5, 1, 0))\n",
        "# arima_model_fit = arima_model.fit()\n",
        "\n",
        "# # Generate ARIMA predictions\n",
        "# arima_predictions = arima_model_fit.forecast(steps=len(Y_test2))[0]\n",
        "\n",
        "# # Combine LSTM and ARIMA predictions\n",
        "# hybrid_predictions = lstm_predictions.flatten() + arima_predictions\n",
        "\n",
        "# # Calculate mean squared error\n",
        "# mse = np.mean((Y_test2 - hybrid_predictions) ** 2)\n",
        "# print(\"Mean Squared Error:\", mse)\n",
        "\n",
        "# # Display model summary\n",
        "# model_lstm.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2HUg_C_Twjy"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Bidirectional, LSTM, Dropout, Dense, Input\n",
        "# from keras.callbacks import EarlyStopping\n",
        "# from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "# # Train LSTM model\n",
        "# # Train LSTM model with tuned hyperparameters\n",
        "# model_lstm = Sequential()\n",
        "# model_lstm.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=(X_train2.shape[1], X_train2.shape[2])))\n",
        "# model_lstm.add(Dropout(0.3))\n",
        "# model_lstm.add(Bidirectional(LSTM(128)))\n",
        "# model_lstm.add(Dense(1))\n",
        "# model_lstm.compile(loss='mean_squared_error', optimizer='adam')\n",
        "# history_lstm = model_lstm.fit(X_train2, Y_train2, epochs=20, batch_size=256,  # Adjusted hyperparameters\n",
        "#                               validation_data=(X_test2, Y_test2),\n",
        "#                               callbacks=[EarlyStopping(monitor='val_loss', patience=6)], verbose=1, shuffle=False)\n",
        "\n",
        "# # Generate LSTM predictions\n",
        "# lstm_predictions = model_lstm.predict(X_test2)\n",
        "\n",
        "# # Fit ARIMA model on the residuals with adjusted ARIMA order\n",
        "# arima_model = ARIMA(residuals, order=(4, 1, 0))  # Adjusted ARIMA order\n",
        "# arima_model_fit = arima_model.fit()\n",
        "\n",
        "# # Generate ARIMA predictions\n",
        "# arima_predictions = arima_model_fit.forecast(steps=len(Y_test2))[0]\n",
        "\n",
        "# # Combine LSTM and ARIMA predictions\n",
        "# hybrid_predictions = lstm_predictions.flatten() + arima_predictions\n",
        "\n",
        "# # Calculate mean squared error\n",
        "# mse = np.mean((Y_test2 - hybrid_predictions) ** 2)\n",
        "# print(\"Mean Squared Error:\", mse)\n",
        "\n",
        "# # Display model summary\n",
        "# model_lstm.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77vi7ivgVKoA"
      },
      "outputs": [],
      "source": [
        "# from keras.layers import SimpleRNN\n",
        "\n",
        "# # Define hybrid model\n",
        "# model_hybrid = Sequential()\n",
        "\n",
        "# # Add the Bidirectional LSTM layer with 100 units in each direction\n",
        "# model_hybrid.add(Bidirectional(LSTM(100, return_sequences=True), input_shape=(X_train2.shape[1], X_train2.shape[2])))\n",
        "\n",
        "# # Add dropout for regularization\n",
        "# model_hybrid.add(Dropout(0.2))\n",
        "\n",
        "# # Add the Echo State Network (ESN) layer (SimpleRNN)\n",
        "# model_hybrid.add(SimpleRNN(100))\n",
        "\n",
        "# # Add the output layer\n",
        "# model_hybrid.add(Dense(1))\n",
        "\n",
        "# # Compile the model\n",
        "# model_hybrid.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# # Fit the model\n",
        "# history_hybrid = model_hybrid.fit(X_train2, Y_train2, epochs=10, batch_size=3200,\n",
        "#                                   validation_data=(X_test2, Y_test2),\n",
        "#                                   callbacks=[EarlyStopping(monitor='val_loss', patience=4)],\n",
        "#                                   verbose=1, shuffle=False)\n",
        "\n",
        "# # Display model summary\n",
        "# model_hybrid.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzAzOzZHVYOM"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Bidirectional, LSTM, Dropout, Dense, Input, Conv1D, Flatten\n",
        "# from keras.callbacks import EarlyStopping\n",
        "# from keras.optimizers import Adam\n",
        "# from tcn import TCN  # You may need to install the 'tcn' package\n",
        "\n",
        "# # Define hybrid model\n",
        "# from keras.layers import Reshape\n",
        "\n",
        "# # Define hybrid model\n",
        "# from keras.layers import Reshape\n",
        "\n",
        "# # Define hybrid model\n",
        "# model_hybrid = Sequential()\n",
        "\n",
        "# # Add a Reshape layer to reshape the input data to include the timestep dimension\n",
        "# model_hybrid.add(Reshape((X_train2.shape[1], X_train2.shape[2]), input_shape=(X_train2.shape[1]*X_train2.shape[2],)))\n",
        "\n",
        "# # Add the Bidirectional LSTM layer with 100 units in each direction\n",
        "# model_hybrid.add(Bidirectional(LSTM(100, return_sequences=True)))\n",
        "\n",
        "# # Add dropout for regularization\n",
        "# model_hybrid.add(Dropout(0.2))\n",
        "\n",
        "# # Add the Echo State Network (ESN) layer (SimpleRNN)\n",
        "# model_hybrid.add(SimpleRNN(100))\n",
        "\n",
        "# # Add the output layer\n",
        "# model_hybrid.add(Dense(1))\n",
        "\n",
        "# # Compile the model\n",
        "# model_hybrid.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# # Fit the model\n",
        "# history_hybrid = model_hybrid.fit(X_train2, Y_train2, epochs=10, batch_size=3200,\n",
        "#                                   validation_data=(X_test2, Y_test2),\n",
        "#                                   callbacks=[EarlyStopping(monitor='val_loss', patience=4)],\n",
        "#                                   verbose=1, shuffle=False)\n",
        "\n",
        "# # Display model summary\n",
        "# model_hybrid.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQJohZ4FQhMo"
      },
      "outputs": [],
      "source": [
        "!pip install keras-tcn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrpUDXOlQVAb"
      },
      "outputs": [],
      "source": [
        "# from keras.layers import SimpleRNN\n",
        "\n",
        "# # Define hybrid model\n",
        "# model_hybrid = Sequential()\n",
        "\n",
        "# # Add the Bidirectional LSTM layer with 100 units in each direction\n",
        "# model_hybrid.add(Bidirectional(LSTM(100, return_sequences=True), input_shape=(X_train2.shape[1], X_train2.shape[2])))\n",
        "\n",
        "# # Add dropout for regularization\n",
        "# model_hybrid.add(Dropout(0.2))\n",
        "\n",
        "# # Add the Echo State Network (ESN) layer (SimpleRNN)\n",
        "# model_hybrid.add(SimpleRNN(100))\n",
        "\n",
        "# # Add the output layer\n",
        "# model_hybrid.add(Dense(1))\n",
        "\n",
        "# # Compile the model\n",
        "# model_hybrid.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# # Fit the model\n",
        "# history_hybrid = model_hybrid.fit(X_train2, Y_train2, epochs=10, batch_size=3200,\n",
        "#                                   validation_data=(X_test2, Y_test2),\n",
        "#                                   callbacks=[EarlyStopping(monitor='val_loss', patience=4)],\n",
        "#                                   verbose=1, shuffle=False)\n",
        "\n",
        "# # Display model summary\n",
        "# model_hybrid.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CnqddnM76Yd"
      },
      "outputs": [],
      "source": [
        "print(\"X_train2 shape:\", X_train2.shape)\n",
        "print(\"Y_train2 shape:\", Y_train2.shape)\n",
        "print(\"X_test2 shape:\", X_test2.shape)\n",
        "print(\"Y_test2 shape:\", Y_test2.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPQjADv5pf9r"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Bidirectional, LSTM, Dropout, Dense\n",
        "# from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# # Define data augmentation parameters\n",
        "# data_augmentation = tf.keras.Sequential([\n",
        "#     tf.keras.layers.RandomRotation(0.2),\n",
        "#     tf.keras.layers.RandomZoom(0.2),\n",
        "#     tf.keras.layers.RandomTranslation(0.2, 0.2),\n",
        "#     # Add more data augmentation layers as needed\n",
        "# ])\n",
        "\n",
        "# # Create generators for training and validation data\n",
        "# # Define the parameters for TimeseriesGenerator\n",
        "# length = 10  # Adjust the length according to your data\n",
        "# sampling_rate = 1\n",
        "# batch_size = 32  # Adjust the batch size as needed\n",
        "\n",
        "# # Create generators for training and validation data\n",
        "# train_data_generator = TimeseriesGenerator(X_train2, Y_train2, length=10, sampling_rate=1, batch_size=32)\n",
        "# val_data_generator = TimeseriesGenerator(X_test2, Y_test2, length=10, sampling_rate=1, batch_size=32)# Create the model\n",
        "# model_hybrid = Sequential()\n",
        "\n",
        "# # Add the Bi-LSTM layer with 100 units in each direction\n",
        "# model_hybrid.add(Bidirectional(LSTM(100, return_sequences=True), input_shape=(1, 30)))\n",
        "\n",
        "# # Add dropout for regularization\n",
        "# model_hybrid.add(Dropout(0.2))\n",
        "\n",
        "# # Add another Bi-LSTM layer, no need for return_sequences here as it's the last LSTM layer\n",
        "# model_hybrid.add(Bidirectional(LSTM(100)))\n",
        "\n",
        "# # Add a Transformer layer (Custom implementation)\n",
        "# class Transformer(tf.keras.layers.Layer):\n",
        "#     def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size,\n",
        "#                  pe_input, pe_target, rate=0.1):\n",
        "#         super(Transformer, self).__init__()\n",
        "#         self.encoder_layers = [tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model) for _ in range(num_layers)]\n",
        "#         self.ffn_layers = [tf.keras.Sequential([tf.keras.layers.Dense(dff, activation='relu'),\n",
        "#                                                  tf.keras.layers.Dense(d_model)]) for _ in range(num_layers)]\n",
        "#         self.num_layers = num_layers\n",
        "#         self.d_model = d_model\n",
        "#         self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "#         self.dropout = tf.keras.layers.Dropout(rate)\n",
        "#         self.norm = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "#     def call(self, inputs, training=True):\n",
        "#         attention_output = self.embedding(inputs)\n",
        "#         for i in range(self.num_layers):\n",
        "#             attention_output = self.encoder_layers[i](attention_output, attention_output)\n",
        "#             attention_output = self.dropout(attention_output, training=training)\n",
        "#             attention_output = self.norm(attention_output + attention_output)  # Residual connection\n",
        "\n",
        "#             ffn_output = self.ffn_layers[i](attention_output)\n",
        "#             ffn_output = self.dropout(ffn_output, training=training)\n",
        "#             attention_output = self.norm(ffn_output + attention_output)  # Residual connection\n",
        "\n",
        "#         return attention_output\n",
        "\n",
        "# transformer_layer = Transformer(num_layers=2, d_model=128, num_heads=2, dff=512,\n",
        "#                                 input_vocab_size=10000, target_vocab_size=10000,\n",
        "#                                 pe_input=10000, pe_target=10000)\n",
        "# model_hybrid.add(transformer_layer)\n",
        "\n",
        "# # Add a dense layer for output\n",
        "# model_hybrid.add(Dense(64, activation='relu'))\n",
        "# model_hybrid.add(Dense(1))\n",
        "\n",
        "# # Define the custom loss function\n",
        "# def custom_loss(y_true, y_pred):\n",
        "#     return tf.keras.losses.mean_squared_error(y_true, y_pred)\n",
        "\n",
        "# # Compile the model with the custom loss function\n",
        "# model_hybrid.compile(loss=custom_loss, optimizer='adam')\n",
        "\n",
        "# # Fit the model using generators\n",
        "# try:\n",
        "#     # Fit the model using generators\n",
        "#     history = model_hybrid.fit(train_data_generator, epochs=10, validation_data=val_data_generator,\n",
        "#                                 callbacks=[EarlyStopping(monitor='val_loss', patience=4)], verbose=1)\n",
        "# except Exception as e:\n",
        "#     print(\"Error occurred during training:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ol_bULL0kMv8"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Bidirectional, LSTM, Dropout, Dense, GRU, Embedding, LayerNormalization, MultiHeadAttention\n",
        "# from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# # Assuming you have X_train2, Y_train2, X_test2, and Y_test2 as your training and testing data\n",
        "\n",
        "# # Create the model\n",
        "# model_hybrid = Sequential()\n",
        "\n",
        "# # Add the Bi-LSTM layer with 100 units in each direction\n",
        "# model_hybrid.add(Bidirectional(LSTM(100, return_sequences=True), input_shape=(X_train2.shape[1], X_train2.shape[2])))\n",
        "\n",
        "# # Add dropout for regularization\n",
        "# model_hybrid.add(Dropout(0.2))\n",
        "\n",
        "# # Add another Bi-LSTM layer, no need for return_sequences here as it's the last LSTM layer\n",
        "# model_hybrid.add(Bidirectional(LSTM(100, return_sequences=True)))\n",
        "\n",
        "# # Add a regularized GRU layer\n",
        "# model_hybrid.add(GRU(100, return_sequences=True, kernel_regularizer='l2'))  # Add return_sequences=True\n",
        "\n",
        "# # Add a Transformer layer\n",
        "# model_hybrid.add(Dense(64, activation='relu'))  # Assuming this as an intermediate layer\n",
        "# model_hybrid.add(Dense(1))\n",
        "\n",
        "# # Compile the model\n",
        "# model_hybrid.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# # Fit the model\n",
        "# history = model_hybrid.fit(X_train2, Y_train2, epochs=10, batch_size=3200, validation_data=(X_test2, Y_test2),\n",
        "#                     callbacks=[EarlyStopping(monitor='val_loss', patience=4)], verbose=1, shuffle=False)\n",
        "\n",
        "# # Display model summary\n",
        "# model_hybrid.summary()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbFYbZExu08M"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Bidirectional, LSTM, Dropout, Dense, GRU, Embedding, LayerNormalization, MultiHeadAttention\n",
        "# from tensorflow.keras.callbacks import EarlyStopping\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# # Assuming you have X_train2, Y_train2, X_test2, and Y_test2 as your training and testing data\n",
        "\n",
        "# # Create the model\n",
        "# model_hybrid = Sequential()\n",
        "\n",
        "# # Add the Bi-LSTM layer with more units and regularization\n",
        "# model_hybrid.add(Bidirectional(LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), input_shape=(X_train2.shape[1], X_train2.shape[2])))\n",
        "\n",
        "# # Add dropout for regularization\n",
        "# model_hybrid.add(Dropout(0.5))\n",
        "\n",
        "# # Add another Bi-LSTM layer with more units and regularization\n",
        "# model_hybrid.add(Bidirectional(LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)))\n",
        "\n",
        "# # Add a regularized GRU layer with more units\n",
        "# model_hybrid.add(GRU(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
        "\n",
        "# # Add a dense layer with more units\n",
        "# model_hybrid.add(Dense(128, activation='relu'))\n",
        "\n",
        "# # Add a dense output layer\n",
        "# model_hybrid.add(Dense(1))\n",
        "\n",
        "# # Compile the model with a lower learning rate and different optimizer\n",
        "# optimizer = Adam(learning_rate=0.0001)\n",
        "# model_hybrid.compile(loss='mean_squared_error', optimizer=optimizer)\n",
        "\n",
        "# # Fit the model with more epochs and batch size\n",
        "# history = model_hybrid.fit(X_train2, Y_train2, epochs=20, batch_size=512, validation_data=(X_test2, Y_test2),\n",
        "#                     callbacks=[EarlyStopping(monitor='val_loss', patience=5)], verbose=1, shuffle=False)\n",
        "\n",
        "# # Display model summary\n",
        "# model_hybrid.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30dGVF5rQ1kR"
      },
      "outputs": [],
      "source": [
        "model1 = Sequential()\n",
        "\n",
        "# Add the Bi-LSTM layer with 100 units in each direction\n",
        "model1.add(Bidirectional(LSTM(100, return_sequences=True), input_shape=(X_train1.shape[1], X_train1.shape[2])))\n",
        "\n",
        "# Add dropout for regularization\n",
        "model1.add(Dropout(0.2))\n",
        "\n",
        "# Add another Bi-LSTM layer, no need for return_sequences here as it's the last LSTM layer\n",
        "model1.add(Bidirectional(LSTM(100)))\n",
        "\n",
        "# Add the output layer\n",
        "model1.add(Dense(1))\n",
        "\n",
        "# Compile the model\n",
        "model1.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# Fit the model\n",
        "history1 = model1.fit(X_train1, Y_train1, epochs=10, batch_size=256, validation_data=(X_test1, Y_test1),\n",
        "                    callbacks=[EarlyStopping(monitor='val_loss', patience=4)], verbose=1, shuffle=False)\n",
        "\n",
        "# Display model summary\n",
        "model1.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tufpUEIo-NDQ"
      },
      "outputs": [],
      "source": [
        "train_predict1 = model1.predict(X_train1)\n",
        "test_predict1 = model1.predict(X_test1)\n",
        "# invert predictions\n",
        "train_predict1 = scaler.inverse_transform(train_predict1)\n",
        "Y_train1_inv = scaler.inverse_transform([Y_train1])\n",
        "test_predict1 = scaler.inverse_transform(test_predict1)\n",
        "Y_test1_inv = scaler.inverse_transform([Y_test1])\n",
        "\n",
        "bilstm_mae = mean_absolute_error(Y_test1_inv[0], test_predict1[:,0])\n",
        "bilstm_rmse = np.sqrt(mean_squared_error(Y_test1[0], test_predict1[:,0]))\n",
        "\n",
        "print('Train Mean Absolute Error:', mean_absolute_error(Y_train1_inv[0], train_predict1[:,0]))\n",
        "print('Train Root Mean Squared Error:',np.sqrt(mean_squared_error(Y_train1_inv[0], train_predict1[:,0])))\n",
        "print('Test Mean Absolute Error:', mean_absolute_error(Y_test1_inv[0], test_predict1[:,0]))\n",
        "print('Test Root Mean Squared Error:',np.sqrt(mean_squared_error(Y_test1_inv[0], test_predict1[:,0])))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bilstm_mae = (Y_test1_inv[0], test_predict1[:,0])\n",
        "bilstm_rmse = np.sqrt(mean_squared_error(Y_test1_inv[0], test_predict1[:,0]))"
      ],
      "metadata": {
        "id": "YVABD5PV_xFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3hWCpJhMDbd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l1, l2  # Import both L1 and L2 for exploration\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Assuming your data is preprocessed and scaled (if necessary)\n",
        "\n",
        "...  # Your testing labels (same shape as Y_train3)\n",
        "\n",
        "# Define hyperparameters (adjust as needed)\n",
        "n_layers = 1  # Experiment with number of GRU layers (start with 1)\n",
        "n_units = 100  # Experiment with number of units per layer\n",
        "learning_rate = 0.001  # Experiment with different learning rates\n",
        "dropout_rate = 0.2  # Experiment with different dropout rates\n",
        "regularizer = l2(0.001)  # Experiment with L1/L2 regularization (start with L2)\n",
        "\n",
        "# Create the GRU model with hyperparameter flexibility\n",
        "def create_gru_model(input_shape, n_layers=1, n_units=64, learning_rate=0.001,\n",
        "                     dropout_rate=0, regularizer=None):\n",
        "\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  for _ in range(n_layers):\n",
        "    return_sequences = True if n_layers > 1 else False  # Adjust for stacked layers\n",
        "    model.add(GRU(n_units, activation='tanh', return_sequences=return_sequences, input_shape=input_shape))\n",
        "    if dropout_rate > 0:\n",
        "      model.add(Dropout(dropout_rate))  # Add dropout for regularization\n",
        "\n",
        "  # Add regularization to Dense layer\n",
        "  model.add(Dense(1, activation='linear', kernel_regularizer=regularizer))\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=learning_rate))\n",
        "\n",
        "  return model\n",
        "\n",
        "# Create the model with appropriate input shape\n",
        "model4 = create_gru_model(X_train3.shape[1:])\n",
        "\n",
        "# Early stopping callback to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=4)\n",
        "\n",
        "# Train the model (adjust epochs and batch size based on dataset size and hardware)\n",
        "history4 = model4.fit(X_train3, Y_train3, epochs=10, batch_size=256,  # May need more epochs\n",
        "                       validation_data=(X_test3, Y_test3), callbacks=[early_stopping], verbose=1, shuffle=False)\n",
        "\n",
        "# Print model summary\n",
        "model4.summary()\n",
        "\n",
        "# Make predictions (optional)\n",
        "predictions = model4.predict(X_test3)  # Get predictions on testing data\n",
        "\n",
        "# You can further process predictions here (e.g., inverse transform if scaling was applied)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfJ0x0CCMGRT"
      },
      "outputs": [],
      "source": [
        "train_predict4 = model4.predict(X_train3)\n",
        "test_predict4 = model4.predict(X_test3)\n",
        "# invert predictions\n",
        "train_predict4 = scaler.inverse_transform(train_predict4)\n",
        "Y_train3_inv = scaler.inverse_transform([Y_train3])\n",
        "test_predict4 = scaler.inverse_transform(test_predict4)\n",
        "Y_test3_inv = scaler.inverse_transform([Y_test3])\n",
        "\n",
        "print('Train Mean Absolute Error:', mean_absolute_error(Y_train3_inv[0], train_predict4[:,0]))\n",
        "print('Train Root Mean Squared Error:',np.sqrt(mean_squared_error(Y_train3_inv[0], train_predict4[:,0])))\n",
        "print('Test Mean Absolute Error:', mean_absolute_error(Y_test3_inv[0], test_predict4[:,0]))\n",
        "print('Test Root Mean Squared Error:',np.sqrt(mean_squared_error(Y_test3_inv[0], test_predict4[:,0])))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rgru_mae = mean_absolute_error(Y_test3[0], test_predict4[:,0])\n",
        "rgru_rmse = np.sqrt(mean_squared_error(Y_test3[0], test_predict4[:,0]))"
      ],
      "metadata": {
        "id": "SOg7je8__lWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZxc55tq1Q9T"
      },
      "outputs": [],
      "source": [
        "#!pip install tensorflow==2.9.1 adabelief-tf==0.2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lybKxkc3WDNT"
      },
      "outputs": [],
      "source": [
        "# #current best 6 may\n",
        "# import numpy as np\n",
        "# from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "# from tensorflow.keras.layers import Concatenate, Dense, LSTM, GRU, Bidirectional, Input, Conv1D, GlobalMaxPooling1D\n",
        "# from tensorflow.keras.models import Model\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "# from xgboost import XGBRegressor\n",
        "# from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "# from tcn import TCN\n",
        "# # Define hyperparameters\n",
        "# lstm_units = 64\n",
        "# gru_units = 64\n",
        "# tcn_filters = 64\n",
        "# tcn_kernel_size = 3\n",
        "# initial_learning_rate = 0.001\n",
        "\n",
        "# # Define the LSTM model\n",
        "# def create_lstm_model(input_shape, units=lstm_units):\n",
        "#     inputs = Input(shape=input_shape)\n",
        "#     x = Bidirectional(LSTM(units, return_sequences=True))(inputs)  # Return sequences\n",
        "#     x = Bidirectional(LSTM(units))(x)\n",
        "#     outputs = Dense(64, activation='relu')(x)  # Added an extra dense layer\n",
        "#     model = Model(inputs=inputs, outputs=outputs)\n",
        "#     optimizer = Adam(learning_rate=initial_learning_rate)\n",
        "#     model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
        "#     return model\n",
        "\n",
        "# # Define the GRU model\n",
        "# def create_gru_model(input_shape, units=gru_units):\n",
        "#     inputs = Input(shape=input_shape)\n",
        "#     x = Bidirectional(GRU(units, return_sequences=True))(inputs)  # Return sequences\n",
        "#     x = Bidirectional(GRU(units))(x)\n",
        "#     outputs = Dense(64, activation='relu')(x)  # Added an extra dense layer\n",
        "#     model = Model(inputs=inputs, outputs=outputs)\n",
        "#     optimizer = Adam(learning_rate=initial_learning_rate)\n",
        "#     model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
        "#     return model\n",
        "\n",
        "# # Define the TCN model\n",
        "# def create_tcn_model(input_shape, filters=tcn_filters, kernel_size=tcn_kernel_size):\n",
        "#     inputs = Input(shape=input_shape)\n",
        "#     # x = Conv1D(filters, kernel_size, activation='relu', padding='same')(inputs)\n",
        "#     x = inputs\n",
        "#     for dilation_rate in [4, 8]:  # Dilation rates for the TCN layers\n",
        "#          x = Conv1D(filters, kernel_size, activation='relu', padding='causal', dilation_rate=dilation_rate)(x)\n",
        "#     x = GlobalMaxPooling1D()(x)  # Global max pooling\n",
        "#     outputs = Dense(64, activation='relu')(x)  # Added an extra dense layer\n",
        "#     model = Model(inputs=inputs, outputs=outputs)\n",
        "#     optimizer = Adam(lr=0.001)\n",
        "#     model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
        "#     return model\n",
        "\n",
        "# # def create_tcn_model(input_shape, filters=tcn_filters, kernel_size=tcn_kernel_size):\n",
        "# #     model = Sequential([\n",
        "# #         Input(shape=input_shape),\n",
        "# #         TCN(nb_filters=64, kernel_size=3, dilations=[ 4, 8, 16], return_sequences=True),\n",
        "# #         Flatten(),\n",
        "# #         Dense(64, activation='relu'),\n",
        "# #         Dense(1)  # Output layer for regression task\n",
        "# #     ])\n",
        "# #     return model\n",
        "\n",
        "# # Create instances of the LSTM, GRU, and TCN models\n",
        "# input_shape_lstm = (X_train4.shape[1], X_train4.shape[2])\n",
        "# input_shape_gru = (X_train4.shape[1], X_train4.shape[2])\n",
        "# input_shape_tcn = (X_train4.shape[1], X_train4.shape[2])\n",
        "\n",
        "# lstm_model = create_lstm_model(input_shape_lstm)\n",
        "# gru_model = create_gru_model(input_shape_gru)\n",
        "# tcn_model_instance = create_tcn_model(input_shape_tcn)\n",
        "\n",
        "# # Define the combined model\n",
        "# def combine_models(lstm_model, gru_model, tcn_model):\n",
        "#     combined_output = Concatenate()([lstm_model.output, gru_model.output, tcn_model.output])\n",
        "#     combined_output = Dense(128, activation='relu')(combined_output)\n",
        "#     combined_output = Dense(64, activation='relu')(combined_output)\n",
        "#     combined_output = Dense(32, activation='relu')(combined_output)\n",
        "#     combined_output = Dense(1)(combined_output)\n",
        "#     combined_model = Model(inputs=[lstm_model.input, gru_model.input, tcn_model.input], outputs=combined_output)\n",
        "#     return combined_model\n",
        "\n",
        "# combined_model = combine_models(lstm_model, gru_model, tcn_model_instance)\n",
        "\n",
        "# # Define learning rate scheduler\n",
        "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.0001)\n",
        "\n",
        "# # Compile the combined model with learning rate scheduler\n",
        "# combined_model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=initial_learning_rate))\n",
        "\n",
        "# # Train the combined model with learning rate scheduler\n",
        "# history_combined = combined_model.fit([X_train4, X_train4, X_train4], Y_train4, epochs=10, batch_size=256,\n",
        "#                                       validation_data=([X_test4, X_test4, X_test4], Y_test4),\n",
        "#                                       callbacks=[EarlyStopping(monitor='val_loss', patience=4),\n",
        "#                                                  reduce_lr],\n",
        "#                                       verbose=1, shuffle=True)\n",
        "\n",
        "\n",
        "# # Display model summary\n",
        "# combined_model.summary()\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.layers import Concatenate, Dense, LSTM, GRU, Bidirectional, Input, Conv1D, GlobalMaxPooling1D, LeakyReLU\n",
        "from tensorflow.keras.models import Model\n",
        "from adabelief_tf import AdaBeliefOptimizer\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from tcn import TCN\n",
        "\n",
        "\n",
        "# Define hyperparameters\n",
        "lstm_units = 64\n",
        "gru_units = 64\n",
        "tcn_filters = 64\n",
        "tcn_kernel_size = 3\n",
        "initial_learning_rate = 0.001\n",
        "dropout_rate = 0.10\n",
        "\n",
        "# Define the LSTM model\n",
        "def create_lstm_model(input_shape, units=lstm_units):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Bidirectional(LSTM(units, return_sequences=True))(inputs)\n",
        "    x = Bidirectional(LSTM(units))(x)\n",
        "    x = Dense(64)(x)\n",
        "    x = LeakyReLU(alpha=0.01)(x)\n",
        "    model = Model(inputs=inputs, outputs=x)\n",
        "    optimizer = AdaBeliefOptimizer(learning_rate=initial_learning_rate, epsilon=1e-14, rectify=True)\n",
        "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
        "    return model\n",
        "\n",
        "# Define the GRU model\n",
        "def create_gru_model(input_shape, units=gru_units):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Bidirectional(GRU(units, return_sequences=True))(inputs)\n",
        "    x = Bidirectional(GRU(units))(x)\n",
        "    x = Dense(64)(x)\n",
        "    x = LeakyReLU(alpha=0.01)(x)\n",
        "    model = Model(inputs=inputs, outputs=x)\n",
        "    optimizer = AdaBeliefOptimizer(learning_rate=initial_learning_rate, epsilon=1e-14, rectify=True)\n",
        "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
        "    return model\n",
        "\n",
        "# Define the TCN model\n",
        "def create_tcn_model(input_shape, filters=tcn_filters, kernel_size=tcn_kernel_size):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    for dilation_rate in [4, 8]:\n",
        "        x = Conv1D(filters, kernel_size, activation='relu', padding='causal', dilation_rate=dilation_rate)(x)\n",
        "    x = GlobalMaxPooling1D()(x)\n",
        "    x = Dense(64)(x)\n",
        "    x = LeakyReLU(alpha=0.01)(x)\n",
        "    model = Model(inputs=inputs, outputs=x)\n",
        "    optimizer = AdaBeliefOptimizer(learning_rate=initial_learning_rate, epsilon=1e-14, rectify=True)\n",
        "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
        "    return model\n",
        "\n",
        "# Create instances of the LSTM, GRU, and TCN models\n",
        "input_shape_lstm = (X_train4.shape[1], X_train4.shape[2])\n",
        "input_shape_gru = (X_train4.shape[1], X_train4.shape[2])\n",
        "input_shape_tcn = (X_train4.shape[1], X_train4.shape[2])\n",
        "\n",
        "lstm_model = create_lstm_model(input_shape_lstm)\n",
        "gru_model = create_gru_model(input_shape_gru)\n",
        "tcn_model_instance = create_tcn_model(input_shape_tcn)\n",
        "\n",
        "# Define the combined model\n",
        "def combine_models(lstm_model, gru_model, tcn_model):\n",
        "    combined_output = Concatenate()([lstm_model.output, gru_model.output, tcn_model.output])\n",
        "    combined_output = Dense(256)(combined_output)\n",
        "    combined_output = LeakyReLU(alpha=0.01)(combined_output)\n",
        "    combined_output = Dropout(dropout_rate)(combined_output)\n",
        "    combined_output = Dense(128)(combined_output)\n",
        "    combined_output = LeakyReLU(alpha=0.01)(combined_output)\n",
        "    combined_output = Dropout(dropout_rate)(combined_output)\n",
        "    combined_output = Dense(64)(combined_output)\n",
        "    combined_output = LeakyReLU(alpha=0.01)(combined_output)\n",
        "    combined_output = Dropout(dropout_rate)(combined_output)\n",
        "    combined_output = Dense(32)(combined_output)\n",
        "    combined_output = LeakyReLU(alpha=0.01)(combined_output)\n",
        "    combined_output = Dense(1)(combined_output)\n",
        "    combined_model = Model(inputs=[lstm_model.input, gru_model.input, tcn_model.input], outputs=combined_output)\n",
        "    return combined_model\n",
        "\n",
        "combined_model = combine_models(lstm_model, gru_model, tcn_model_instance)\n",
        "\n",
        "# Define learning rate scheduler\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.0001)\n",
        "\n",
        "# Compile the combined model with AdaBelief optimizer\n",
        "combined_model.compile(loss='mean_squared_error', optimizer=AdaBeliefOptimizer(learning_rate=initial_learning_rate, epsilon=1e-14, rectify=True))\n",
        "\n",
        "# Train the combined model with learning rate scheduler\n",
        "history_combined = combined_model.fit([X_train4, X_train4, X_train4], Y_train4, epochs=10, batch_size=1200,\n",
        "                                      validation_data=([X_test4, X_test4, X_test4], Y_test4),\n",
        "                                      callbacks=[EarlyStopping(monitor='val_loss', patience=4),\n",
        "                                                 reduce_lr],\n",
        "                                      verbose=1, shuffle=True)\n",
        "\n",
        "# Display model summary\n",
        "combined_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1c4Tg0AznK6x"
      },
      "outputs": [],
      "source": [
        "lstm_predictions_test = lstm_model.predict(X_test4)\n",
        "gru_predictions_test = gru_model.predict(X_test4)\n",
        "tcn_predictions_test = tcn_model_instance.predict(X_test4)\n",
        "comb_test = combined_model.predict([X_test4, X_test4, X_test4])\n",
        "\n",
        "lstm_predictions_train = lstm_model.predict(X_train4)\n",
        "gru_predictions_train = gru_model.predict(X_train4)\n",
        "tcn_predictions_train = tcn_model_instance.predict(X_train4)\n",
        "comb_train = combined_model.predict([X_train4, X_train4, X_train4])\n",
        "\n",
        "\n",
        "\n",
        "# Combine predictions with original test features\n",
        "combined_features_test = np.concatenate([X_test4.reshape(X_test4.shape[0], -1), comb_test, lstm_predictions_test, gru_predictions_test, tcn_predictions_test], axis=1)\n",
        "combined_features_train = np.concatenate([X_train4.reshape(X_train4.shape[0], -1), comb_train, lstm_predictions_train, gru_predictions_train, tcn_predictions_train], axis=1)\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Define XGBRegressor model\n",
        "xgb_model = XGBRegressor()\n",
        "\n",
        "# Train XGBRegressor on combined features\n",
        "xgb_model.fit(combined_features_train, Y_train4)\n",
        "\n",
        "test_predictions = xgb_model.predict(combined_features_test)\n",
        "\n",
        "# Inverse transform the predictions and actual values\n",
        "test_predictions_inv = scaler.inverse_transform(test_predictions.reshape(-1, 1))  # Reshape predictions to match scaler dimensions\n",
        "Y_test4_inv = scaler.inverse_transform(Y_test4.reshape(-1, 1))  # Reshape actual values to match scaler dimensions\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "test_mae = mean_absolute_error(Y_test4_inv, test_predictions_inv)\n",
        "test_rmse = np.sqrt(mean_squared_error(Y_test4_inv, test_predictions_inv))\n",
        "\n",
        "\n",
        "print('Test Mean Absolute Error:', test_mae)\n",
        "print('Test Root Mean Squared Error:', test_rmse)\n",
        "\n",
        "comb_test_inv = scaler.inverse_transform(comb_test);\n",
        "\n",
        "\n",
        "tm = mean_absolute_error( Y_test4_inv, comb_test_inv)\n",
        "print(tm)\n",
        "tr = np.sqrt(mean_squared_error( Y_test4_inv, comb_test_inv))\n",
        "print(tr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOmZ2yZXGX1A"
      },
      "outputs": [],
      "source": [
        " #!pip install keras-tcn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xouu7oI3F8OU"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense, Input, Conv1D, Flatten\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "# from tensorflow.keras.callbacks import EarlyStopping\n",
        "# from tcn import TCN\n",
        "\n",
        "# # Define the TCN model\n",
        "# def create_tcn_model(input_shape):\n",
        "#     model = Sequential([\n",
        "#         Input(shape=input_shape),\n",
        "#         TCN(nb_filters=64, kernel_size=3, dilations=[1, 2, 4, 8, 16, 32], return_sequences=True),\n",
        "#         Flatten(),\n",
        "#         Dense(64, activation='relu'),\n",
        "#         Dense(1)  # Output layer for regression task\n",
        "#     ])\n",
        "#     return model\n",
        "\n",
        "# # Define input shape (assuming input shape is (timesteps, features))\n",
        "# input_shape = X_train5.shape[1:]\n",
        "\n",
        "# # Create and compile the TCN model\n",
        "# tcn_model = create_tcn_model(input_shape)\n",
        "# tcn_model.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error')\n",
        "\n",
        "# # Define early stopping callback to prevent overfitting\n",
        "# early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# # Train the model\n",
        "# history = tcn_model.fit(X_train5, Y_train5, epochs=10, batch_size=256,\n",
        "#                         validation_data=(X_test5, Y_test5), callbacks=[early_stopping])\n",
        "\n",
        "# # Evaluate the model on the test data\n",
        "# test_loss = tcn_model.evaluate(X_test5, Y_test5)\n",
        "\n",
        "# # Print the test loss\n",
        "# print(\"Test Loss:\", test_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxZRNQX6BUtC"
      },
      "outputs": [],
      "source": [
        "# from xgboost import XGBRegressor\n",
        "\n",
        "# # Define XGBRegressor model\n",
        "# xgb_model = XGBRegressor()\n",
        "\n",
        "# # Train XGBRegressor on combined features\n",
        "# xgb_model.fit(combined_features_test, Y_test4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j26lpyAsT0KT"
      },
      "outputs": [],
      "source": [
        "# test_predictions = xgb_model.predict(combined_features_test)\n",
        "\n",
        "# # Inverse transform the predictions and actual values\n",
        "# test_predictions_inv = scaler.inverse_transform(test_predictions.reshape(-1, 1))  # Reshape predictions to match scaler dimensions\n",
        "# Y_test4_inv = scaler.inverse_transform(Y_test4.reshape(-1, 1))  # Reshape actual values to match scaler dimensions\n",
        "\n",
        "# comb_test_inv = scaler.inverse_transform(comb_test);\n",
        "# y_test_inv = scaler.inverse_transform(Y_test4);\n",
        "\n",
        "# # Calculate evaluation metrics\n",
        "# test_mae = mean_absolute_error(Y_test4_inv, test_predictions_inv)\n",
        "# test_rmse = np.sqrt(mean_squared_error(Y_test4_inv, test_predictions_inv))\n",
        "\n",
        "# print('Test Mean Absolute Error:', test_mae)\n",
        "# print('Test Root Mean Squared Error:', test_rmse)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPPqXXXxFo95"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIIc1KasFPGP"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade keras-lr-finder\n",
        "\n",
        "# from keras_lr_finder import LearningRateFinder\n",
        "# !pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Q9KxZKonsM2"
      },
      "outputs": [],
      "source": [
        "# !pip install tensorflow==2.11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oMmgMa_rO2K"
      },
      "outputs": [],
      "source": [
        "# %reload_ext autoreload\n",
        "# %autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHli20ys5dJK"
      },
      "outputs": [],
      "source": [
        "X_train3.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f7TjBLc_W1j"
      },
      "outputs": [],
      "source": [
        "# # Load the TensorBoard notebook extension\n",
        "# %load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJoC_TRW5WS4"
      },
      "outputs": [],
      "source": [
        "# %tensorboard --logdir logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tFBrw4M4A7s"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# # Save the visualization as an image file\n",
        "# #plot_model(hybrid_model, to_file='hybrid_model.png', show_shapes=True)\n",
        "\n",
        "# # Alternatively, display the model directly in Jupyter Notebook\n",
        "# plot_model(hybrid_model, show_shapes=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x82FYmECl2OJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, GRU, Dropout, Conv1D, BatchNormalization, Activation, GlobalAveragePooling1D, Dense, Permute, concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Assuming you have the following dataset shapes:\n",
        "# X_train5.shape = (num_samples, 1, MAX_SEQUENCE_LENGTH)\n",
        "# Y_train5.shape = (num_samples, NB_CLASS)\n",
        "# X_test5.shape = (num_samples, 1, MAX_SEQUENCE_LENGTH)\n",
        "# Y_test5.shape = (num_samples, NB_CLASS)\n",
        "\n",
        "# Parameters\n",
        "MAX_SEQUENCE_LENGTH = X_train5.shape[2]\n",
        "NB_CLASS = Y_train5.shape[1] if len(Y_train5.shape) > 1 else 1\n",
        "\n",
        "def generate_GRU_FCN_model(input_shape, nb_class):\n",
        "    inp = Input(shape=input_shape)\n",
        "\n",
        "    # GRU part\n",
        "    x_r = GRU(8)(inp)  # GRU with 8 units\n",
        "    x_r = Dropout(0.8)(x_r)  # 80% dropout\n",
        "\n",
        "    # Convolutional part\n",
        "    y = Permute((2, 1))(inp)\n",
        "    y = Conv1D(128, 8, padding='same', kernel_initializer='he_uniform')(y)  # 128 filters\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "\n",
        "    y = Conv1D(256, 5, padding='same', kernel_initializer='he_uniform')(y)  # 256 filters\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "\n",
        "    y = Conv1D(128, 3, padding='same', kernel_initializer='he_uniform')(y)  # 128 filters\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "\n",
        "    y = GlobalAveragePooling1D()(y)\n",
        "\n",
        "    x = concatenate([x_r, y])\n",
        "\n",
        "    output = Dense(nb_class, activation='softmax' if nb_class > 1 else 'linear')(x)\n",
        "\n",
        "    model = Model(inp, output)\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define input shape\n",
        "input_shape = (1, MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "# Generate the model\n",
        "model5 = generate_GRU_FCN_model(input_shape, NB_CLASS)\n",
        "\n",
        "# Compile the model\n",
        "model5.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error' if NB_CLASS == 1 else 'categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history5 = model5.fit(X_train5, Y_train5, epochs=10, batch_size=128, validation_split=0.2, verbose=1, shuffle=True)\n",
        "\n",
        "# Predict on test set\n",
        "predictions5 = model5.predict(X_test5)\n",
        "\n",
        "# If it's a regression task, you may want to calculate metrics like MAE and RMSE\n",
        "if NB_CLASS == 1:\n",
        "    test_mae = mean_absolute_error(Y_test5, predictions5)\n",
        "    test_rmse = np.sqrt(mean_squared_error(Y_test5, predictions5))\n",
        "    print('Test Mean Absolute Error:', test_mae)\n",
        "    print('Test Root Mean Squared Error:', test_rmse)\n",
        "else:\n",
        "    # For classification tasks, you might use accuracy or other classification metrics\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    test_acc = accuracy_score(np.argmax(Y_test5, axis=1), np.argmax(predictions5, axis=1))\n",
        "    print('Test Accuracy:', test_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4Nmd9uymMiN"
      },
      "outputs": [],
      "source": [
        "\n",
        "predictions5_inv = scaler.inverse_transform(predictions5)\n",
        "Y_test5_inv = scaler.inverse_transform([Y_test5])\n",
        "\n",
        "grufcn_mae = mean_absolute_error(Y_test5_inv[0], predictions5_inv[:,0])\n",
        "grufcn_rmse = np.sqrt(mean_squared_error(Y_test5_inv[0], predictions5_inv[:,0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNKD39hQe0y0"
      },
      "outputs": [],
      "source": [
        "#train_losses_lstm = history.history['loss']\n",
        "#val_losses_lstm = history.history['val_loss']\n",
        "train_losses_bilstm = history1.history['loss']\n",
        "val_losses_bilstm = history1.history['val_loss']\n",
        "# train_losses_gru = history2.history['loss']\n",
        "# val_losses_gru = history2.history['val_loss']\n",
        "train_losses_rgru = history4.history['loss']\n",
        "val_losses_rgru = history4.history['val_loss']\n",
        "\n",
        "train_losses_hybrid = history_combined.history['loss']\n",
        "val_losses_hybrid = history_combined.history['val_loss']\n",
        "train_losses_grufcn = history5.history['loss']\n",
        "val_losses_grufcn = history5.history['val_loss']\n",
        "epochs_grufcn = len(history5.history['val_loss'])\n",
        "plt.plot(range(epochs_grufcn), val_losses_grufcn, label='grufcn', marker='o')\n",
        "# for epoch in range(10):  # Adjust the number of epochs based on your data\n",
        "#   train_losses_bilstm.append(0.2 * epoch)  # Example training loss for model 1\n",
        "#   val_losses_bilstm.append(0.15 * epoch)  # Example validation loss for model 1\n",
        "#   train_losses_gru.append(0.2 * epoch)  # Example training loss for model 1\n",
        "#   val_losses_gru.append(0.15 * epoch)\n",
        "#   train_losses_rgru.append(0.2 * epoch)  # Example training loss for model 1\n",
        "#   val_losses_rgru.append(0.15 * epoch)\n",
        "#   # ... Repeat for other models (replace with your actual data)\n",
        "\n",
        "# # Create the plot\n",
        "# plt.figure(figsize=(12, 6))\n",
        "\n",
        "# # Plot training losses\n",
        "# plt.plot(range(30), train_losses_bilstm, label='Model 1 Train Loss', marker='o')\n",
        "# plt.plot(range(10), train_losses_gru, label='Model 2 Train Loss', marker='s')\n",
        "# plt.plot(range(10), train_losses_rgru, label='Model 3 Train Loss', marker='^')\n",
        "#plt.plot(range(100), model4_train_losses, label='Model 4 Train Loss', marker='x')\n",
        "\n",
        "# Plot validation losses (optional, comment out if not available)\n",
        "# plt.plot(range(100), model1_val_losses, label='Model 1 Val Loss', marker='o', linestyle='--')\n",
        "# plt.plot(range(100), model2_val_losses, label='Model 2 Val Loss', marker='s', linestyle='--')\n",
        "# plt.plot(range(100), model3_val_losses, label='Model 3 Val Loss', marker='^', linestyle='--')\n",
        "# plt.plot(range(100), model4_val_losses, label='Model 4 Val Loss', marker='x', linestyle='--')\n",
        "\n",
        "#epochs_lstm = len(history.history['val_loss'])\n",
        "epochs_bilstm = len(history1.history['val_loss'])\n",
        "# epochs_gru = len(history2.history['val_loss'])\n",
        "epochs_rgru = len(history4.history['val_loss'])\n",
        "epochs_hybrid = len(history_combined.history['val_loss'])\n",
        "\n",
        "plt.plot(range(epochs_bilstm), val_losses_bilstm, label='BiLSTM Loss', marker='o')\n",
        "# plt.plot(range(epochs_gru), train_losses_gru, label='GRU Loss', marker='s')\n",
        "plt.plot(range(epochs_rgru), val_losses_rgru, label='R.GRU Loss', marker='^')\n",
        "#plt.plot(range(epochs_lstm), train_losses_lstm, label='LSTM Loss', marker='o')\n",
        "plt.plot(range(epochs_hybrid), val_losses_hybrid, label='Hybrid Loss', marker='s')\n",
        "\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Validation Loss of Different Models')\n",
        "\n",
        "# Add legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FD5-mLZSaLN-"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.plot(history1.history['val_loss'], label='Validation Loss')\n",
        "\n",
        "plt.plot(history4.history['val_loss'], label='Validation Loss BiLstm')\n",
        "\n",
        "plt.plot(history_combined.history['val_loss'], label='Validation Loss Hybrid')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTmWT5B_rcyF"
      },
      "outputs": [],
      "source": [
        "# train_predict = model.predict(X_train)\n",
        "# test_predict = model.predict(X_test)\n",
        "# # invert predictions\n",
        "# train_predict = scaler.inverse_transform(train_predict)\n",
        "# Y_train = scaler.inverse_transform([Y_train])\n",
        "# test_predict = scaler.inverse_transform(test_predict)\n",
        "# Y_test = scaler.inverse_transform([Y_test])\n",
        "\n",
        "# print('Train Mean Absolute Error:', mean_absolute_error(Y_train[0], train_predict[:,0]))\n",
        "# print('Train Root Mean Squared Error:',np.sqrt(mean_squared_error(Y_train[0], train_predict[:,0])))\n",
        "# print('Test Mean Absolute Error:', mean_absolute_error(Y_test[0], test_predict[:,0]))\n",
        "# print('Test Root Mean Squared Error:',np.sqrt(mean_squared_error(Y_test[0], test_predict[:,0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjKsfaTXtG84"
      },
      "outputs": [],
      "source": [
        "# # Predictions for the combined model\n",
        "# train_predict_combined = combined_model.predict([X_train4, X_train4])\n",
        "# test_predict_combined = combined_model.predict([X_test4, X_test4])\n",
        "\n",
        "# # Invert predictions if needed\n",
        "# # Assuming you have a scaler object named 'scaler'\n",
        "# train_predict_combined = scaler.inverse_transform(train_predict_combined)\n",
        "# Y_train4_inv = scaler.inverse_transform([Y_train4])\n",
        "# test_predict_combined = scaler.inverse_transform(test_predict_combined)\n",
        "# Y_test4_inv = scaler.inverse_transform([Y_test4])\n",
        "\n",
        "# # Calculate and print evaluation metrics\n",
        "# from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# print('Train Mean Absolute Error:', mean_absolute_error(Y_train4_inv[0], train_predict_combined[:, 0]))\n",
        "# print('Train Root Mean Squared Error:', np.sqrt(mean_squared_error(Y_train4_inv[0], train_predict_combined[:, 0])))\n",
        "# print('Test Mean Absolute Error:', mean_absolute_error(Y_test4_inv[0], test_predict_combined[:, 0]))\n",
        "# print('Test Root Mean Squared Error:', np.sqrt(mean_squared_error(Y_test4_inv[0], test_predict_combined[:, 0])))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuTQrCsfDBNt"
      },
      "outputs": [],
      "source": [
        "# train_predict2 = model2.predict(X_train2)\n",
        "# test_predict2 = model2.predict(X_test2)\n",
        "# # invert predictions\n",
        "# train_predict2 = scaler.inverse_transform(train_predict2)\n",
        "# Y_train2 = scaler.inverse_transform([Y_train2])\n",
        "# test_predict2 = scaler.inverse_transform(test_predict2)\n",
        "# Y_test2 = scaler.inverse_transform([Y_test2])\n",
        "\n",
        "# print('Train Mean Absolute Error:', mean_absolute_error(Y_train2[0], train_predict2[:,0]))\n",
        "# print('Train Root Mean Squared Error:',np.sqrt(mean_squared_error(Y_train2[0], train_predict2[:,0])))\n",
        "# print('Test Mean Absolute Error:', mean_absolute_error(Y_test2[0], test_predict2[:,0]))\n",
        "# print('Test Root Mean Squared Error:',np.sqrt(mean_squared_error(Y_test2[0], test_predict2[:,0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpUSEm0J9-5j"
      },
      "outputs": [],
      "source": [
        "# train_predict3 = model3.predict(X_train3)\n",
        "# test_predict3 = model3.predict(X_test3)\n",
        "# # invert predictions\n",
        "# train_predict3 = scaler.inverse_transform(train_predict3)\n",
        "# Y_train3 = scaler.inverse_transform([Y_train3])\n",
        "# test_predict3 = scaler.inverse_transform(test_predict3)\n",
        "# Y_test3 = scaler.inverse_transform([Y_test3])\n",
        "\n",
        "# print('Train Mean Absolute Error:', mean_absolute_error(Y_train3[0], train_predict3[:,0]))\n",
        "# print('Train Root Mean Squared Error:',np.sqrt(mean_squared_error(Y_train3[0], train_predict3[:,0])))\n",
        "# print('Test Mean Absolute Error:', mean_absolute_error(Y_test3[0], test_predict3[:,0]))\n",
        "# print('Test Root Mean Squared Error:',np.sqrt(mean_squared_error(Y_test3[0], test_predict3[:,0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAsEw5NpO0ED"
      },
      "outputs": [],
      "source": [
        "# train_predict_hybrid = hybrid_model.predict([X_train4,X_train4])\n",
        "# test_predict_hybrid = hybrid_model.predict([X_test4,X_test4])\n",
        "# # invert predictions\n",
        "# train_predict_hybrid = scaler.inverse_transform(train_predict_hybrid)\n",
        "# Y_train4 = scaler.inverse_transform([Y_train4])\n",
        "# test_predict_hybrid = scaler.inverse_transform(test_predict_hybrid)\n",
        "# Y_test4 = scaler.inverse_transform([Y_test4])\n",
        "\n",
        "# print('Train Mean Absolute Error:', mean_absolute_error(Y_train4[0], train_predict_hybrid[:,0]))\n",
        "# print('Train Root Mean Squared Error:',np.sqrt(mean_squared_error(Y_train4[0], train_predict_hybrid[:,0])))\n",
        "# print('Test Mean Absolute Error:', mean_absolute_error(Y_test4[0], test_predict_hybrid[:,0]))\n",
        "# print('Test Root Mean Squared Error:',np.sqrt(mean_squared_error(Y_test4[0], test_predict_hybrid[:,0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rbeiv_Dr9_XA"
      },
      "outputs": [],
      "source": [
        "# from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# # Make predictions using the hybrid model for X_train4 and X_train5\n",
        "# train_predict_hybrid_4 = hybrid_model.predict([X_train4, X_train5, X_train4, X_train5])\n",
        "# test_predict_hybrid_4 = hybrid_model.predict([X_test4, X_test5, X_test4, X_test5])\n",
        "\n",
        "# # Invert predictions for X_train4\n",
        "# train_predict_hybrid_4 = scaler.inverse_transform(train_predict_hybrid_4)\n",
        "# Y_train_hybrid_4 = scaler.inverse_transform([Y_train4])\n",
        "# test_predict_hybrid_4 = scaler.inverse_transform(test_predict_hybrid_4)\n",
        "# Y_test_hybrid_4 = scaler.inverse_transform([Y_test4])\n",
        "\n",
        "# # Calculate errors for X_train4\n",
        "# train_mae_hybrid_4 = mean_absolute_error(Y_train_hybrid_4[0], train_predict_hybrid_4[:, 0])\n",
        "# train_rmse_hybrid_4 = np.sqrt(mean_squared_error(Y_train_hybrid_4[0], train_predict_hybrid_4[:, 0]))\n",
        "# test_mae_hybrid_4 = mean_absolute_error(Y_test_hybrid_4[0], test_predict_hybrid_4[:, 0])\n",
        "# test_rmse_hybrid_4 = np.sqrt(mean_squared_error(Y_test_hybrid_4[0], test_predict_hybrid_4[:, 0]))\n",
        "\n",
        "# # Invert predictions for X_train5\n",
        "# train_predict_hybrid_5 = hybrid_model.predict([X_train5, X_train4, X_train5, X_train4])\n",
        "# test_predict_hybrid_5 = hybrid_model.predict([X_test5, X_test4, X_test5, X_test4])\n",
        "\n",
        "# # Invert predictions for X_train5\n",
        "# train_predict_hybrid_5 = scaler.inverse_transform(train_predict_hybrid_5)\n",
        "# Y_train_hybrid_5 = scaler.inverse_transform([Y_train5])\n",
        "# test_predict_hybrid_5 = scaler.inverse_transform(test_predict_hybrid_5)\n",
        "# Y_test_hybrid_5 = scaler.inverse_transform([Y_test5])\n",
        "\n",
        "# # Calculate errors for X_train5\n",
        "# train_mae_hybrid_5 = mean_absolute_error(Y_train_hybrid_5[0], train_predict_hybrid_5[:, 0])\n",
        "# train_rmse_hybrid_5 = np.sqrt(mean_squared_error(Y_train_hybrid_5[0], train_predict_hybrid_5[:, 0]))\n",
        "# test_mae_hybrid_5 = mean_absolute_error(Y_test_hybrid_5[0], test_predict_hybrid_5[:, 0])\n",
        "# test_rmse_hybrid_5 = np.sqrt(mean_squared_error(Y_test_hybrid_5[0], test_predict_hybrid_5[:, 0]))\n",
        "\n",
        "# # Combine predictions and actual values\n",
        "# train_predict_combined = np.concatenate((train_predict_hybrid_4, train_predict_hybrid_5), axis=0)\n",
        "# test_predict_combined = np.concatenate((test_predict_hybrid_4, test_predict_hybrid_5), axis=0)\n",
        "# Y_train_combined = np.concatenate((Y_train_hybrid_4, Y_train_hybrid_5), axis=1).flatten()\n",
        "# Y_test_combined = np.concatenate((Y_test_hybrid_4, Y_test_hybrid_5), axis=1).flatten()\n",
        "\n",
        "# # Calculate combined errors\n",
        "# train_mae_combined = mean_absolute_error(Y_train_combined, train_predict_combined)\n",
        "# train_rmse_combined = np.sqrt(mean_squared_error(Y_train_combined, train_predict_combined))\n",
        "# test_mae_combined = mean_absolute_error(Y_test_combined, test_predict_combined)\n",
        "# test_rmse_combined = np.sqrt(mean_squared_error(Y_test_combined, test_predict_combined))\n",
        "\n",
        "# # Print combined errors\n",
        "# print('Train Mean Absolute Error (Hybrid Model - Combined):', train_mae_combined)\n",
        "# print('Train Root Mean Squared Error (Hybrid Model - Combined):', train_rmse_combined)\n",
        "# print('Test Mean Absolute Error (Hybrid Model - Combined):', test_mae_combined)\n",
        "# print('Test Root Mean Squared Error (Hybrid Model - Combined):', test_rmse_combined)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RM4f1gfaos9c"
      },
      "outputs": [],
      "source": [
        "# # Predictions on training and testing data\n",
        "# train_predict_hybrid = hybrid_model.predict([X_train4, X_train4, X_train4, X_train4])\n",
        "# test_predict_hybrid = hybrid_model.predict([X_test4, X_test4, X_test4, X_test4])\n",
        "\n",
        "# # Invert predictions\n",
        "# train_predict_hybrid = scaler.inverse_transform(train_predict_hybrid)\n",
        "# Y_train4_inv = scaler.inverse_transform([Y_train4])\n",
        "# test_predict_hybrid = scaler.inverse_transform(test_predict_hybrid)\n",
        "# Y_test4_inv = scaler.inverse_transform([Y_test4])\n",
        "\n",
        "# # Evaluate the performance\n",
        "# train_mae_hybrid = mean_absolute_error(Y_train4_inv[0], train_predict_hybrid[:,0])\n",
        "# train_rmse_hybrid = np.sqrt(mean_squared_error(Y_train4_inv[0], train_predict_hybrid[:,0]))\n",
        "# test_mae_hybrid = mean_absolute_error(Y_test4_inv[0], test_predict_hybrid[:,0])\n",
        "# test_rmse_hybrid = np.sqrt(mean_squared_error(Y_test4_inv[0], test_predict_hybrid[:,0]))\n",
        "\n",
        "# # Print evaluation metrics\n",
        "# print('Train Mean Absolute Error:', train_mae_hybrid)\n",
        "# print('Train Root Mean Squared Error:', train_rmse_hybrid)\n",
        "# print('Test Mean Absolute Error:', test_mae_hybrid)\n",
        "# print('Test Root Mean Squared Error:', test_rmse_hybrid)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOQX1bfKri9s"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(history1.history['loss'], label='Train Loss BiLSTM')\n",
        "plt.plot(history1.history['val_loss'], label='Test Loss BiLSTM')\n",
        "plt.plot(history4.history['loss'], label='Train Loss RGRU')\n",
        "plt.plot(history4.history['val_loss'], label='Test Loss RGRU')\n",
        "# plt.plot(history2.history['loss'], label='Train Loss  GRU')\n",
        "# plt.plot(history2.history['val_loss'], label='Test Loss GRU')\n",
        "# plt.plot(history3.history['loss'], label='Train Loss RGRU')\n",
        "# plt.plot(history3.history['val_loss'], label='Test Loss RGRU')\n",
        "plt.plot(history_combined.history['loss'], label='Train Loss hybrid')\n",
        "plt.plot(history_combined.history['val_loss'], label='Test Loss hybrid')\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMLCj4OvlDzl"
      },
      "outputs": [],
      "source": [
        "Y_test = scaler.inverse_transform([Y_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-aK7ItxsT0I"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "aa = [x for x in range(100)]\n",
        "# Creating a figure object with desired figure size\n",
        "plt.figure(figsize=(20, 6))\n",
        "\n",
        "# Plotting the actual values in blue with a dot marker\n",
        "actual_value = Y_test\n",
        "\n",
        "# Plot the actual values\n",
        "plt.plot(aa, Y_test[0][:100], marker='.', label=\"actual\", color='black')\n",
        "plt.plot(aa, test_predict4[:100], '.-', linewidth=1.0, label=\"Regularised GRU prediction\", color='blue')\n",
        "# Plotting the predicted values with very thin lines and adjusted colors for better visibility\n",
        "# plt.plot(aa, test_predict[:, 0][:200], '.-', label=\"LSTM prediction\", color='red', linewidth=0.5)\n",
        "plt.plot(aa, test_predict1[:, 0][:100], '.-', linewidth=1.0, label=\"BiLSTM prediction\", color='green')\n",
        "# plt.plot(aa, test_predict2[:, 0][:200], '.-', label=\"GRU prediction\", color='purple', linewidth=0.7)\n",
        "#plt.plot(aa, comb_test_inv[:, 0][:100], '.-', label=\"Hybrid\", color='red', linewidth=0.8)\n",
        "plt.plot(aa, test_predictions_inv[:100], '.-', label=\"Hybrid prediction\", color='#FF337A', linewidth=0.8)\n",
        "plt.plot(aa, predictions5_inv[:100], '.-', label=\"GRUFCN\", color='purple', linewidth=0.5)\n",
        "# Removing the top spines\n",
        "sns.despine(top=True)\n",
        "\n",
        "# Adjusting the subplot location\n",
        "plt.subplots_adjust(left=0.07)\n",
        "\n",
        "# Labeling the y-axis\n",
        "plt.ylabel('Global_active_power', size=14)\n",
        "\n",
        "# Labeling the x-axis\n",
        "plt.xlabel('Time step', size=14)\n",
        "\n",
        "# Adding a legend with font size of 15\n",
        "plt.legend(fontsize=16)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hr7gUufE3wpN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "aa = [x for x in range(100)]\n",
        "# Creating a figure object with desired figure size\n",
        "plt.figure(figsize=(20, 6))\n",
        "\n",
        "# Plotting the actual values in blue with a dot marker\n",
        "plt.plot(aa, Y_test[0][80:180], marker='.', label=\"actual\", color='black')\n",
        "\n",
        "# Plotting the predicted values with adjusted colors for better visibility\n",
        "plt.plot(aa, test_predict1[:, 0][80:180], '.-', label=\"BiLSTM prediction\", color='green', linewidth=1.0)  # Reddish\n",
        "plt.plot(aa, test_predict4[:, 0][80:180], '.-', linewidth=1.0, label=\"RGRU prediction\", color='blue')  # Greenish\n",
        "# plt.plot(aa, test_predict2[:, 0][:50], '.-', label=\"GRU prediction\", color='#7A33FF', linewidth=0.7)  # Purplish\n",
        "# plt.plot(aa, test_predict3[:, 0][:50], '.-', label=\"Regularised GRU prediction\", color='#336BFF', linewidth=0.8)  # Bluish\n",
        "plt.plot(aa, test_predictions_inv[:, 0][80:180], '.-', label=\"Hybrid prediction\", color='red', linewidth=1.0)  # Pinkish\n",
        "\n",
        "\n",
        "# Removing the top spines\n",
        "sns.despine(top=True)\n",
        "\n",
        "# Adjusting the subplot location\n",
        "plt.subplots_adjust(left=0.07)\n",
        "\n",
        "# Labeling the y-axis\n",
        "plt.ylabel('Global_active_power', size=14)\n",
        "\n",
        "# Labeling the x-axis\n",
        "plt.xlabel('Time step', size=14)\n",
        "\n",
        "# Adding a legend with font size of 15\n",
        "plt.legend(fontsize=16)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdfUioiFIEIi"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "aa = [x for x in range(1, 26)]  # Range adjusted from 1 to 20\n",
        "\n",
        "# Creating a figure object with desired figure size\n",
        "plt.figure(figsize=(20, 6))\n",
        "\n",
        "# Plotting the actual values in blue with a dot marker\n",
        "plt.plot(aa, Y_test[0][175:200], marker='.', label=\"actual\", color='black')\n",
        "\n",
        "# Plotting the predicted values with adjusted colors for better visibility\n",
        "plt.plot(aa, test_predict1[:, 0][175:200], '.-', label=\"BiLSTM prediction\", color='yellow')\n",
        "plt.plot(aa, test_predict4[:, 0][175:200], '.-', linewidth=1.0, label=\"R GRU prediction\", color='green')\n",
        "# plt.plot(aa, test_predict2[:, 0][:20], '.-', label=\"GRU prediction\", color='purple')\n",
        "# plt.plot(aa, test_predict3[:, 0][:20], '.-', label=\"Regularised GRU prediction\", color='blue')\n",
        "plt.plot(aa, test_predictions_inv[:, 0][175:200], '.-', label=\"Hybrid prediction\", color='#FF337A', linewidth=1.5)\n",
        "\n",
        "# Removing the top spines\n",
        "sns.despine(top=True)\n",
        "\n",
        "# Adjusting the subplot location\n",
        "plt.subplots_adjust(left=0.07)\n",
        "\n",
        "# Labeling the y-axis\n",
        "plt.ylabel('Global_active_power', size=14)\n",
        "\n",
        "# Labeling the x-axis\n",
        "plt.xlabel('Time step', size=14)\n",
        "\n",
        "# Adding a legend with font size of 15\n",
        "plt.legend(fontsize=16)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhYzrexu2Myr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_error_table(Y_test, test_predict, dates):\n",
        "    error_table = {}\n",
        "    date_count = {}\n",
        "\n",
        "    for date, actual, predicted in zip(dates, Y_test, test_predict):\n",
        "        absolute_error = np.abs(actual - predicted[0])\n",
        "        if actual > 0:\n",
        "            error = (absolute_error / actual) * 100\n",
        "        else:\n",
        "            error = 0  # Handling case where actual value is zero\n",
        "        if date not in date_count:\n",
        "            date_count[date] = 0\n",
        "            error_table[date] = 0\n",
        "        date_count[date] += 1\n",
        "        error_table[date] += error\n",
        "\n",
        "    for date in error_table:\n",
        "        error_table[date] /= date_count[date]\n",
        "\n",
        "    return error_table\n",
        "\n",
        "# Example usage\n",
        "#error_percentages_lstm = calculate_error_table(Y_test[0], test_predict, d_test)\n",
        "error_percentages_bilstm = calculate_error_table(Y_test1_inv[0], test_predict1, d_test1)\n",
        "# # error_percentages_Regularised_gru = calculate_error_table(Y_test2[0], test_predict2, d_test2)\n",
        "error_percentages_rgru = calculate_error_table(Y_test3_inv[0], test_predict4, d_test3)\n",
        "error_percentages_hybrid = calculate_error_table(Y_test4_inv, test_predictions_inv, d_test4)\n",
        "error_percentages_GRUFCN = calculate_error_table(Y_test5_inv[0], predictions5_inv, d_test5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_Uvfgi448aq"
      },
      "outputs": [],
      "source": [
        "# percentage_df = pd.DataFrame(zip(error_percentages_lstm.keys(), error_percentages_lstm.values(), error_percentages_bilstm.values(), error_percentages_gru.values(), error_percentages_Regularised_gru.values(), error_percentages_hybrid.values()), columns=[\"Date\", \"LSTM(%)\", \"BiLSTM(%)\", \"GRU(%)\", \"Reg.GRU(%)\", \"HybridModel(%)\"])\n",
        "\n",
        "# percentage_df.tail(40)\n",
        "\n",
        "percentage_df = pd.DataFrame(zip(error_percentages_bilstm.keys(), error_percentages_bilstm.values(), error_percentages_rgru.values(), error_percentages_hybrid.values(),error_percentages_GRUFCN.values()), columns=[\"Date\",  \"BiLSTM(%)\",\"R.GRU(%)\",  \"HybridModel(%)\",\"GRUFCN\"])\n",
        "\n",
        "percentage_df.tail(40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGNmwBZkLKQb"
      },
      "outputs": [],
      "source": [
        "average_error_GRUFCN = percentage_df[\"GRUFCN\"].mean()\n",
        "average_error_hybrid = percentage_df[\"hybrid\"].mean()\n",
        "print(average_error_GRUFCN)\n",
        "print(average_error_hybrid)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaLCqF5x6lHc"
      },
      "outputs": [],
      "source": [
        "#average_error_lstm = percentage_df[\"LSTM(%)\"].mean()\n",
        "average_error_bilstm = percentage_df[\"BiLSTM(%)\"].mean()\n",
        "# average_error_gru = percentage_df[\"GRU(%)\"].mean()\n",
        "average_error_Reg_gru = percentage_df[\"R.GRU(%)\"].mean()\n",
        "average_error_hybrid = percentage_df[\"HybridModel(%)\"].mean()\n",
        "\n",
        "# max_value = 100  # Replace with the actual maximum value if known\n",
        "# average_error_lstm = (percentage_df[\"LSTM(%)\"] / max_value).mean()\n",
        "# average_error_bilstm = (percentage_df[\"BiLSTM(%)\"] / max_value).mean()\n",
        "# average_error_gru = (percentage_df[\"GRU(%)\"] / max_value).mean()\n",
        "average_error_GRUFCN = percentage_df[\"GRUFCN\"].mean()\n",
        "\n",
        "print(average_error_bilstm)\n",
        "# print(average_error_gru)\n",
        "print(average_error_Reg_gru)\n",
        "print(average_error_hybrid)\n",
        "print(average_error_GRUFCN)\n",
        "# Find the method with the lowest average error\n",
        "best_method = None\n",
        "# lowest_error = min(average_error_lstm, average_error_bilstm, average_error_gru, average_error_Reg_gru, average_error_hybrid)\n",
        "lowest_error = min( average_error_bilstm, average_error_Reg_gru, average_error_hybrid, average_error_GRUFCN)\n",
        "if lowest_error == average_error_bilstm:\n",
        " best_method = \"BiLSTM\"\n",
        "elif lowest_error == average_error_Reg_gru:\n",
        " best_method = \"RGRU\"\n",
        "elif lowest_error == average_error_GRUFCN:\n",
        " best_method = \"GRUFCN\"\n",
        "else:\n",
        " best_method = \"Hybrid\"\n",
        "\n",
        "# Print the DataFrame with additional information\n",
        "print(percentage_df)\n",
        "print(f\"\\nOverall Best Method: {best_method} \")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "bilstm_rmse =\n",
        "bilstm_mae =\n",
        "rgru_rmse =\n",
        "rgru_mae =\n",
        "grufcn_rmse = 0.007291528\n",
        "grufcn_mae = 0.01837317\n",
        "test_rmse = 0.076008976\n",
        "test_mae = 0.20441817\n",
        "\n",
        "# Define models and their corresponding RMSE and MAE values\n",
        "model_names = ['BiLSTM', 'R. GRU', 'Hybrid', 'GRUFCN']  # Add your model names here\n",
        "test_rmsed = [bilstm_rmse, rgru_rmse, test_rmse, grufcn_rmse]  # RMSE values for Model A, Model B, and Model C\n",
        "test_maed = [bilstm_mae, rgru_mae, test_mae, grufcn_mae]   # MAE values for Model A, Model B, and Model C\n",
        "\n",
        "# Create a figure and axis\n",
        "fig, ax = plt.subplots(figsize=(10, 7))\n",
        "\n",
        "# Set bar colors using a colormap\n",
        "colors = plt.cm.tab10(np.arange(len(model_names)))\n",
        "\n",
        "# Define positions for bars\n",
        "x_pos = np.arange(len(model_names))\n",
        "\n",
        "# Set width for the bars\n",
        "width = 0.4\n",
        "\n",
        "# Plot RMSE bars\n",
        "for i in range(len(model_names)):\n",
        "    ax.bar(x_pos[i] - width/2, test_rmsed[i], width=width, color=colors[i], label=model_names[i])\n",
        "\n",
        "# Plot MAE bars\n",
        "for i in range(len(model_names)):\n",
        "    ax.bar(x_pos[i] + width/2, test_maed[i], width=width, color=colors[i], alpha=0.5)\n",
        "\n",
        "# Set tick labels and axis labels\n",
        "ax.set_xticks(x_pos)\n",
        "ax.set_xticklabels(model_names, rotation=45, ha='right')\n",
        "ax.set_ylabel('Values', fontsize=12)\n",
        "ax.set_title('RMSE and MAE Comparison of Different Models', fontsize=14)\n",
        "\n",
        "# Create custom legend\n",
        "handles = [plt.Rectangle((0,0),1,1, color=colors[i]) for i in range(len(model_names))]\n",
        "ax.legend(handles, model_names, loc='upper left')\n",
        "\n",
        "# Show plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0PbaWHSO-hva"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}